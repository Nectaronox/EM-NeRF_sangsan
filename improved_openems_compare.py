#!/usr/bin/env python3
"""
ê°œì„ ëœ EM-NeRF vs FDTD vs MoM ì¢…í•© ì„±ëŠ¥ ë¹„êµ ì‹œìŠ¤í…œ
- ë” ì •êµí•œ ë©”íŠ¸ë¦­ ì‹œìŠ¤í…œ
- í†µê³„ì  ìœ ì˜ì„± ê²€ì¦
- ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…
- í™•ì¥ ê°€ëŠ¥í•œ ì•„í‚¤í…ì²˜
"""

import numpy as np
import time
import matplotlib.pyplot as plt
import seaborn as sns
from dataclasses import dataclass, field
from typing import Dict, List, Tuple, Optional, Any, Callable
from pathlib import Path
from datetime import datetime
import logging
import json
import pickle
from abc import ABC, abstractmethod
import psutil
import os
from contextlib import contextmanager
from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor
import warnings
from scipy import stats
import pandas as pd

# PyTorch ë° EM-NeRF ê´€ë ¨ import
try:
    import torch
    import torch.nn as nn
    import torch.nn.functional as F
    from torch.utils.data import DataLoader
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("âš ï¸  PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. EM-NeRF ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# EM-NeRF ëª¨ë¸ í´ë˜ìŠ¤ import ì‹œë„


# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('em_benchmark.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class BenchmarkMetrics:
    """í™•ì¥ëœ ë²¤ì¹˜ë§ˆí¬ ë©”íŠ¸ë¦­"""
    method_name: str
    scenario: str
    
    # ì •í™•ë„ ë©”íŠ¸ë¦­
    mse_error: float
    mae_error: float
    relative_error: float
    correlation_coeff: float
    
    # ì„±ëŠ¥ ë©”íŠ¸ë¦­  
    computation_time: float
    memory_peak: float
    memory_average: float
    cpu_usage: float
    
    # ìˆ˜ë ´ì„± ë©”íŠ¸ë¦­
    convergence_iterations: int
    convergence_time: float
    numerical_stability: float
    
    # ì£¼íŒŒìˆ˜ ì •ë³´
    frequency_range: Tuple[float, float]
    frequency_points: int
    
    # ì¶”ê°€ ì •ë³´
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    @property
    def accuracy_score(self) -> float:
        """ì¢…í•© ì •í™•ë„ ì ìˆ˜ (0-1)"""
        # ì—¬ëŸ¬ ë©”íŠ¸ë¦­ì„ ì¢…í•©í•œ ì ìˆ˜
        mse_score = np.exp(-self.mse_error)
        mae_score = np.exp(-self.mae_error) 
        rel_score = np.exp(-self.relative_error)
        corr_score = abs(self.correlation_coeff)
        
        return (mse_score + mae_score + rel_score + corr_score) / 4
    
    @property
    def efficiency_score(self) -> float:
        """íš¨ìœ¨ì„± ì ìˆ˜ (ì†ë„ + ë©”ëª¨ë¦¬)"""
        # ì •ê·œí™”ëœ ì‹œê°„ê³¼ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê¸°ë°˜
        time_score = 1.0 / (1.0 + self.computation_time)
        memory_score = 1.0 / (1.0 + self.memory_peak / 1000)  # GB ë‹¨ìœ„
        
        return (time_score + memory_score) / 2

@dataclass 
class ScenarioConfig:
    """ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì •"""
    name: str
    complexity: str  # 'low', 'medium', 'high', 'extreme'
    geometry_type: str  # 'simple', 'moderate', 'complex', 'urban'
    frequency: Optional[float] = None
    frequency_range: Optional[Tuple[float, float]] = None
    frequency_points: int = 50
    
    # ë¬¼ë¦¬ì  ë§¤ê°œë³€ìˆ˜
    dimensions: Tuple[float, float, float] = (1.0, 1.0, 1.0)  # ë¯¸í„°
    material_properties: Dict[str, float] = field(default_factory=dict)
    boundary_conditions: str = 'pml'
    
    # ìˆ˜ì¹˜ì  ë§¤ê°œë³€ìˆ˜
    mesh_resolution: float = 0.01  # ë¯¸í„°
    convergence_threshold: float = 1e-6
    max_iterations: int = 1000
    
    # ì˜ˆìƒ ì„±ëŠ¥
    expected_advantage: str = 'unknown'
    difficulty_level: int = 1  # 1-10 ìŠ¤ì¼€ì¼

class EMSolverInterface(ABC):
    """ì „ìê¸° í•´ì„ê¸° ì¸í„°í˜ì´ìŠ¤"""
    
    @abstractmethod
    def solve_scenario(self, scenario: ScenarioConfig) -> Dict[str, np.ndarray]:
        """ì‹œë‚˜ë¦¬ì˜¤ í•´ì„"""
        pass
    
    @abstractmethod
    def get_solver_info(self) -> Dict[str, Any]:
        """í•´ì„ê¸° ì •ë³´"""
        pass
    
    @abstractmethod
    def validate_scenario(self, scenario: ScenarioConfig) -> bool:
        """ì‹œë‚˜ë¦¬ì˜¤ ìœ íš¨ì„± ê²€ì‚¬"""
        pass

class OpenEMSInterface(EMSolverInterface):
    """OpenEMS FDTD ì¸í„°í˜ì´ìŠ¤"""
    
    def __init__(self):
        self.solver_name = "OpenEMS_FDTD"
        self.version = "0.0.35"
        
    def solve_scenario(self, scenario: ScenarioConfig) -> Dict[str, np.ndarray]:
        """FDTD ì‹œë®¬ë ˆì´ì…˜ ì‹¤í–‰"""
        logger.info(f"FDTD ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘: {scenario.name}")
        
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” OpenEMS Python API ì‚¬ìš©
        # ì—¬ê¸°ì„œëŠ” ì‹œë®¬ë ˆì´ì…˜ëœ ê²°ê³¼ ìƒì„±
        np.random.seed(42)  # ì¬í˜„ì„±ì„ ìœ„í•´
        
        # ì£¼íŒŒìˆ˜ ì„¤ì •
        if scenario.frequency:
            freqs = np.array([scenario.frequency])
        elif scenario.frequency_range:
            freqs = np.linspace(scenario.frequency_range[0], 
                              scenario.frequency_range[1],
                              scenario.frequency_points)
        else:
            freqs = np.array([2.4e9])  # ê¸°ë³¸ê°’
        
        # ê³µê°„ ê·¸ë¦¬ë“œ ìƒì„±
        grid_size = int(max(scenario.dimensions) / scenario.mesh_resolution)
        x = np.linspace(0, scenario.dimensions[0], grid_size)
        y = np.linspace(0, scenario.dimensions[1], grid_size)
        z = np.linspace(0, scenario.dimensions[2], grid_size)
        
        # ë³µì¡ë„ì— ë”°ë¥¸ ì‹œë®¬ë ˆì´ì…˜ ì‹œê°„ ëª¨ë¸ë§
        complexity_factor = {'low': 1, 'medium': 5, 'high': 20, 'extreme': 100}
        base_time = complexity_factor.get(scenario.complexity, 1)
        time.sleep(base_time * 0.01)  # ì‹¤ì œ ê³„ì‚° ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
        
        # ê²°ê³¼ ìƒì„± (ì‹¤ì œë¡œëŠ” OpenEMSì—ì„œ ê³„ì‚°ë¨)
        results = self._generate_fdtd_results(x, y, z, freqs, scenario)
        
        return results
    
    def _generate_fdtd_results(self, x, y, z, freqs, scenario):
        """FDTD ê²°ê³¼ ìƒì„± (ì‹œë®¬ë ˆì´ì…˜)"""
        # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” OpenEMS ê²°ê³¼ë¥¼ ë°˜í™˜
        nx, ny, nz = len(x), len(y), len(z)
        nf = len(freqs)
        
        # ì•ˆí…Œë‚˜ íŒ¨í„´ ì‹œë®¬ë ˆì´ì…˜
        X, Y, Z = np.meshgrid(x, y, z, indexing='ij')
        
        # ì „ê¸°ì¥ (ë³µì†Œìˆ˜)
        E_field = np.zeros((nx, ny, nz, 3, nf), dtype=complex)
        H_field = np.zeros((nx, ny, nz, 3, nf), dtype=complex)
        
        for i, freq in enumerate(freqs):
            k = 2 * np.pi * freq / 3e8  # íŒŒìˆ˜
            
            # ê°„ë‹¨í•œ ë‹¤ì´í´ ë°©ì‚¬ íŒ¨í„´
            r = np.sqrt(X**2 + Y**2 + Z**2)
            theta = np.arccos(Z / (r + 1e-10))
            phi = np.arctan2(Y, X)
            
            # ë³µì¡ë„ì— ë”°ë¥¸ íŒ¨í„´ ë³€í™”
            if scenario.complexity == 'high':
                # ë³µì¡í•œ ì‚°ë€ íŒ¨í„´ ì¶”ê°€
                scatter_factor = np.sin(k * X) * np.cos(k * Y) * np.exp(-Z/10)
            else:
                scatter_factor = 1.0
            
            # E-field ê³„ì‚°
            E_r = np.zeros_like(r)
            E_theta = (1j * k / r) * np.sin(theta) * np.exp(-1j * k * r) * scatter_factor
            E_phi = np.zeros_like(r)
            
            # êµ¬ë©´ ì¢Œí‘œê³„ì—ì„œ ì§êµ ì¢Œí‘œê³„ë¡œ ë³€í™˜
            E_field[:, :, :, 0, i] = (E_r * np.sin(theta) * np.cos(phi) + 
                                     E_theta * np.cos(theta) * np.cos(phi) - 
                                     E_phi * np.sin(phi))
            E_field[:, :, :, 1, i] = (E_r * np.sin(theta) * np.sin(phi) + 
                                     E_theta * np.cos(theta) * np.sin(phi) + 
                                     E_phi * np.cos(phi))
            E_field[:, :, :, 2, i] = E_r * np.cos(theta) - E_theta * np.sin(theta)
            
            # H-field (Maxwell ë°©ì •ì‹ìœ¼ë¡œë¶€í„°)
            Z0 = 377  # ììœ ê³µê°„ ì„í”¼ë˜ìŠ¤
            H_field[:, :, :, :, i] = E_field[:, :, :, :, i] / Z0
        
        return {
            'E_field': E_field,
            'H_field': H_field,
            'frequencies': freqs,
            'coordinates': (x, y, z),
            'convergence_iterations': scenario.max_iterations // 2,
            'solver_info': self.get_solver_info()
        }
    
    def get_solver_info(self) -> Dict[str, Any]:
        return {
            'name': self.solver_name,
            'version': self.version,
            'method': 'FDTD',
            'capabilities': ['broadband', 'time_domain', 'nonlinear']
        }
    
    def validate_scenario(self, scenario: ScenarioConfig) -> bool:
        # ê¸°ë³¸ ê²€ì¦
        return True

class EMNeRFInterface(EMSolverInterface):
    """ì‹¤ì œ í•™ìŠµëœ EM-NeRF ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ì¸í„°í˜ì´ìŠ¤"""
    
    def __init__(self, model_path: Optional[str] = None, device: str = 'auto'):
        self.solver_name = "EM-NeRF"
        self.model_path = model_path
        self.model = None
        
        # âœ… ì •ê·œí™” íŒŒë¼ë¯¸í„° íŒŒì¼ ë¡œë“œ
        if Path(norm_params_path).exists():
            logger.info(f"ì •ê·œí™” íŒŒë¼ë¯¸í„° ë¡œë“œ ì¤‘: {norm_params_path}")
            with open(norm_params_path, 'r') as f:
                params = json.load(f)
            self.pos_min = np.array(params['pos_min'])
            self.pos_max = np.array(params['pos_max'])
            logger.info("âœ… ì •ê·œí™” íŒŒë¼ë¯¸í„° ë¡œë“œ ì™„ë£Œ!")
        else:
            logger.warning(f"âš ï¸ ì •ê·œí™” íŒŒë¼ë¯¸í„° íŒŒì¼({norm_params_path})ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¶€ì •í™•í•œ ê²°ê³¼ê°€ ë‚˜ì˜¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

        self.is_loaded = False
        
        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        if device == 'auto':
            self.device = 'cuda' if torch.cuda.is_available() else 'cpu' if TORCH_AVAILABLE else None
        else:
            self.device = device
            
        if not TORCH_AVAILABLE:
            logger.error("PyTorchê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ EM-NeRFë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
            
        if model_path:
            self.load_model(model_path)
    
    def load_model(self, model_path: str):
        """ì‹¤ì œ í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ"""
            
        try:
            logger.info(f"EM-NeRF ëª¨ë¸ ë¡œë“œ ì‹œì‘: {model_path}")
            
            # ëª¨ë¸ ê²½ë¡œ í™•ì¸
            if not Path(model_path).exists():
                logger.error(f"ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}")
                return False
            
            # ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (saved modelì˜ êµ¬ì¡°ì™€ ì¼ì¹˜í•´ì•¼ í•¨)
            self.model = FixedStabilizedEMNeRF(hidden_dim=128, n_layers=6)
            
            # ì €ì¥ëœ state_dict ë¡œë“œ
            checkpoint = torch.load(model_path, map_location=self.device)
            
            # state_dict ì²˜ë¦¬ (í‚¤ ì´ë¦„ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŒ)
            if isinstance(checkpoint, dict):
                if 'model_state_dict' in checkpoint:
                    state_dict = checkpoint['model_state_dict']
                elif 'state_dict' in checkpoint:
                    state_dict = checkpoint['state_dict']
                else:
                    state_dict = checkpoint
            else:
                state_dict = checkpoint
            
            # ëª¨ë¸ì— ê°€ì¤‘ì¹˜ ë¡œë“œ
            self.model.load_state_dict(state_dict, strict=False)
            self.model.to(self.device)
            self.model.eval()  # ì¶”ë¡  ëª¨ë“œ
            
            self.is_loaded = True
            logger.info(f"âœ… EM-NeRF ëª¨ë¸ ë¡œë“œ ì„±ê³µ! (ë””ë°”ì´ìŠ¤: {self.device})")
            return True
            
        except Exception as e:
            logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.is_loaded = False
            return False
    
    def _prepare_model_inputs(self, scenario: ScenarioConfig) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
        """ëª¨ë¸ ì…ë ¥ ë°ì´í„° ì¤€ë¹„"""
        # ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´ì—ì„œ ì…ë ¥ ë°ì´í„° ìƒì„±
        
        # ì£¼íŒŒìˆ˜ ì„¤ì •
        if scenario.frequency:
            freqs = np.array([scenario.frequency])
        elif scenario.frequency_range:
            freqs = np.linspace(scenario.frequency_range[0], 
                              scenario.frequency_range[1],
                              scenario.frequency_points)
        else:
            freqs = np.array([2.4e9])  # ê¸°ë³¸ê°’
        
        # ê³µê°„ ê·¸ë¦¬ë“œ ìƒì„± (ì‹œë‚˜ë¦¬ì˜¤ ì°¨ì› ê¸°ë°˜)
        grid_size = min(32, int(max(scenario.dimensions) / scenario.mesh_resolution))  # ë©”ëª¨ë¦¬ ì ˆì•½
        
        x = np.linspace(0, scenario.dimensions[0], grid_size)
        y = np.linspace(0, scenario.dimensions[1], grid_size)
        z = np.linspace(0, scenario.dimensions[2], grid_size)
        
        # ë©”ì‰¬ê·¸ë¦¬ë“œ ìƒì„±
        X, Y, Z = np.meshgrid(x, y, z, indexing='ij')
        positions = np.stack([X.flatten(), Y.flatten(), Z.flatten()], axis=1)
        
        positions = positions / np.max(scenario.dimensions) # [0, 1] ë²”ìœ„ë¡œ ì •ê·œí™”
        
        # ì£¼íŒŒìˆ˜ ì •ê·œí™” (ë¡œê·¸ ìŠ¤ì¼€ì¼)
        freq_norm = np.log10(np.clip(freqs[0], 1e6, 1e12))  # ì²« ë²ˆì§¸ ì£¼íŒŒìˆ˜ë§Œ ì‚¬ìš©
        freq_norm = (freq_norm - 6) / 6  # [-1, 1] ë²”ìœ„ë¡œ ì •ê·œí™”
        
        # ë°°ì¹˜ ì°¨ì› ë§ì¶”ê¸°
        n_points = positions.shape[0]
        
        # PyTorch í…ì„œë¡œ ë³€í™˜
        positions = torch.FloatTensor(positions).to(self.device)
        frequencies = torch.FloatTensor(np.full((n_points, 1), freq_norm)).to(self.device)
        times = torch.zeros(n_points, 1).to(self.device)  # ì‹œê°„ì€ 0ìœ¼ë¡œ ì„¤ì •
        
        # ë™ì  ê°ì²´ (ì‹œë‚˜ë¦¬ì˜¤ ë³µì¡ë„ì— ë”°ë¼ ì„¤ì •)
        complexity_factor = {'low': 0.1, 'medium': 0.3, 'high': 0.7, 'extreme': 1.0}
        obj_val = complexity_factor.get(scenario.complexity, 0.3)
        dynamic_objects = torch.full((n_points, 8), obj_val).to(self.device)
        
        return positions, frequencies, times, dynamic_objects, (grid_size, grid_size, grid_size)
    
    def _postprocess_model_outputs(self, outputs: Dict, grid_shape: Tuple) -> Dict[str, np.ndarray]:
        """ëª¨ë¸ ì¶œë ¥ í›„ì²˜ë¦¬"""
        results = {}
        
        # ì „ê¸°ì¥ê³¼ ìê¸°ì¥ì„ ì˜¬ë°”ë¥¸ í˜•íƒœë¡œ ë³€í™˜
        E_field = outputs['electric_field'].detach().cpu().numpy()
        H_field = outputs['magnetic_field'].detach().cpu().numpy()
        
        # ê·¸ë¦¬ë“œ í˜•íƒœë¡œ ì¬êµ¬ì„±
        nx, ny, nz = grid_shape
        
        # 5D ë°°ì—´ë¡œ ì¬êµ¬ì„±: (nx, ny, nz, 3_components, 1_frequency)
        E_field_reshaped = E_field.reshape(nx, ny, nz, 3)
        H_field_reshaped = H_field.reshape(nx, ny, nz, 3)
        
        # ì£¼íŒŒìˆ˜ ì°¨ì› ì¶”ê°€ (OpenEMS í˜•íƒœì™€ í˜¸í™˜)
        results['E_field'] = E_field_reshaped[..., np.newaxis]
        results['H_field'] = H_field_reshaped[..., np.newaxis]
        
        # ì¢Œí‘œê³„ ìƒì„±
        x = np.linspace(0, 1, nx)  # ì •ê·œí™”ëœ ì¢Œí‘œ
        y = np.linspace(0, 1, ny)
        z = np.linspace(0, 1, nz)
        results['coordinates'] = (x, y, z)
        
        # ì£¼íŒŒìˆ˜ ì •ë³´
        results['frequencies'] = np.array([2.4e9])  # ê¸°ë³¸ê°’
        
        # ìˆ˜ë ´ ì •ë³´ (ë¹ ë¥¸ ìˆ˜ë ´ íŠ¹ì„±)
        results['convergence_iterations'] = 10
        
        # ì¶”ê°€ ì •ë³´
        results['solver_info'] = self.get_solver_info()
        
        # ì‚°ë€ ê³„ìˆ˜ì™€ ì§€ì—° ì •ë³´ë„ ì¶”ê°€
        if 'scattering_coefficient' in outputs:
            scattering = outputs['scattering_coefficient'].detach().cpu().numpy()
            results['scattering_coefficient'] = scattering.reshape(nx, ny, nz)
        
        if 'propagation_delay' in outputs:
            delay = outputs['propagation_delay'].detach().cpu().numpy()
            results['propagation_delay'] = delay.reshape(nx, ny, nz)
        
        return results
    
    def solve_scenario(self, scenario: ScenarioConfig) -> Dict[str, np.ndarray]:
        """ì‹¤ì œ EM-NeRF ëª¨ë¸ë¡œ ì‹œë‚˜ë¦¬ì˜¤ í•´ì„"""
        if not self.is_loaded:
            logger.error("EM-NeRF ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            # Fallback: ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ
            return self._fallback_simulation(scenario)
        
        logger.info(f"ğŸ§  EM-NeRF ì¶”ë¡  ì‹œì‘: {scenario.name}")
        
        try:
            with torch.no_grad():  # ì¶”ë¡  ëª¨ë“œì—ì„œ gradient ê³„ì‚° ë¹„í™œì„±í™”
                # 1. ì…ë ¥ ë°ì´í„° ì¤€ë¹„
                positions, frequencies, times, dynamic_objects, grid_shape = \
                    self._prepare_model_inputs(scenario)
                
                # 2. ëª¨ë¸ ì¶”ë¡  (ë°°ì¹˜ ì²˜ë¦¬)
                batch_size = 1024  # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•œ ë°°ì¹˜ í¬ê¸°
                n_points = positions.shape[0]
                all_outputs = {
                    'electric_field': [],
                    'magnetic_field': [],
                    'scattering_coefficient': [],
                    'propagation_delay': []
                }
                
                # ë°°ì¹˜ë³„ë¡œ ì²˜ë¦¬
                for i in range(0, n_points, batch_size):
                    end_idx = min(i + batch_size, n_points)
                    
                    pos_batch = positions[i:end_idx]
                    freq_batch = frequencies[i:end_idx]
                    time_batch = times[i:end_idx]
                    obj_batch = dynamic_objects[i:end_idx]
                    
                    # ëª¨ë¸ ì‹¤í–‰
                    batch_outputs = self.model(pos_batch, freq_batch, time_batch, obj_batch)
                    
                    # ê²°ê³¼ ìˆ˜ì§‘
                    for key in all_outputs.keys():
                        if key in batch_outputs:
                            all_outputs[key].append(batch_outputs[key])
                
                # ë°°ì¹˜ ê²°ê³¼ í•©ì¹˜ê¸°
                final_outputs = {}
                for key, values in all_outputs.items():
                    if values:  # ë¹„ì–´ìˆì§€ ì•Šì€ ê²½ìš°
                        final_outputs[key] = torch.cat(values, dim=0)
                
                # 3. í›„ì²˜ë¦¬
                results = self._postprocess_model_outputs(final_outputs, grid_shape)
                
                logger.info(f"âœ… EM-NeRF ì¶”ë¡  ì™„ë£Œ: {scenario.name}")
                return results
                
        except Exception as e:
            logger.error(f"âŒ EM-NeRF ì¶”ë¡  ì‹¤íŒ¨: {e}")
            # Fallback: ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ
            return self._fallback_simulation(scenario)
    
    def _fallback_simulation(self, scenario: ScenarioConfig) -> Dict[str, np.ndarray]:
        """ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ"""
        logger.warning("ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ë™ì‘í•©ë‹ˆë‹¤.")
        
        # FDTD ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì‹œë®¬ë ˆì´ì…˜
        fdtd_solver = OpenEMSInterface()
        ground_truth = fdtd_solver.solve_scenario(scenario)
        
        # NeRF íŠ¹ì„±: ë¹ ë¥´ì§€ë§Œ ì•½ê°„ì˜ ì˜¤ì°¨
        prediction_error = 0.03 * scenario.difficulty_level / 10
        
        # ê²°ê³¼ì— ì˜ˆì¸¡ ì˜¤ì°¨ ì¶”ê°€
        results = {}
        for key, value in ground_truth.items():
            if isinstance(value, np.ndarray) and key in ['E_field', 'H_field']:
                noise_scale = np.abs(value) * prediction_error
                noise = np.random.normal(0, noise_scale)
                results[key] = value + noise
            else:
                results[key] = value
        
        # ë¹ ë¥¸ ì¶”ë¡  ì‹œê°„ (0.05ì´ˆ)
        time.sleep(0.05)
        
        return results
    
    def get_solver_info(self) -> Dict[str, Any]:
        return {
            'name': self.solver_name,
            'method': 'Neural_Radiance_Fields',
            'capabilities': ['fast_inference', 'scene_representation', 'interpolation'],
            'model_loaded': self.is_loaded,
            'device': self.device if hasattr(self, 'device') else 'unknown',
            'model_path': self.model_path
        }
    
    def validate_scenario(self, scenario: ScenarioConfig) -> bool:
        """ì‹œë‚˜ë¦¬ì˜¤ ìœ íš¨ì„± ê²€ì‚¬"""
        if not TORCH_AVAILABLE or not EMNERF_MODEL_AVAILABLE:
            return False
        return True  # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¼ë„ ë™ì‘ ê°€ëŠ¥

class MoMInterface(EMSolverInterface):
    """Method of Moments ì¸í„°í˜ì´ìŠ¤"""
    
    def __init__(self):
        self.solver_name = "Method_of_Moments"
        
    def solve_scenario(self, scenario: ScenarioConfig) -> Dict[str, np.ndarray]:
        """MoM í•´ì„"""
        logger.info(f"MoM í•´ì„ ì‹œì‘: {scenario.name}")
        
        # MoMì€ ë³µì¡í•œ êµ¬ì¡°ì—ì„œ ìˆ˜ë ´ì„± ë¬¸ì œ ìˆìŒ
        if scenario.complexity in ['high', 'extreme']:
            logger.warning("MoM: ê³ ë³µì¡ë„ ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ìˆ˜ë ´ì„± ë¬¸ì œ ê°€ëŠ¥")
        
        # FDTD ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ MoM íŠ¹ì„± ë°˜ì˜
        fdtd_solver = OpenEMSInterface()
        ground_truth = fdtd_solver.solve_scenario(scenario)
        
        # MoM íŠ¹ì„±: ì¤‘ê°„ ì •í™•ë„, ì¤‘ê°„ ì†ë„
        complexity_factor = {'low': 0.02, 'medium': 0.05, 'high': 0.15, 'extreme': 0.3}
        error_level = complexity_factor.get(scenario.complexity, 0.1)
        
        # ê³„ì‚° ì‹œê°„ ì‹œë®¬ë ˆì´ì…˜
        time_factor = {'low': 0.5, 'medium': 2, 'high': 8, 'extreme': 30}
        calc_time = time_factor.get(scenario.complexity, 2)
        time.sleep(calc_time * 0.01)
        
        # ê²°ê³¼ ìƒì„±
        results = {}
        for key, value in ground_truth.items():
            if isinstance(value, np.ndarray) and key in ['E_field', 'H_field']:
                error = np.random.normal(0, np.abs(value) * error_level)
                results[key] = value + error
            else:
                results[key] = value
        
        return results
    
    def get_solver_info(self) -> Dict[str, Any]:
        return {
            'name': self.solver_name,
            'method': 'Method_of_Moments',
            'capabilities': ['frequency_domain', 'conducting_surfaces', 'wire_antennas']
        }
    
    def validate_scenario(self, scenario: ScenarioConfig) -> bool:
        return True

class ResourceMonitor:
    """ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§"""
    
    def __init__(self):
        self.process = psutil.Process()
        self.monitoring = False
        self.measurements = []
    
    @contextmanager
    def monitor(self):
        """ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì»¨í…ìŠ¤íŠ¸"""
        self.start_monitoring()
        try:
            yield self
        finally:
            self.stop_monitoring()
    
    def start_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì‹œì‘"""
        self.monitoring = True
        self.measurements = []
        self.initial_memory = self.process.memory_info().rss / 1024 / 1024
    
    def stop_monitoring(self):
        """ëª¨ë‹ˆí„°ë§ ì¤‘ì§€"""
        self.monitoring = False
    
    def take_measurement(self):
        """í˜„ì¬ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ ì¸¡ì •"""
        if self.monitoring:
            memory_mb = self.process.memory_info().rss / 1024 / 1024
            cpu_percent = self.process.cpu_percent()
            
            self.measurements.append({
                'timestamp': time.time(),
                'memory_mb': memory_mb,
                'cpu_percent': cpu_percent
            })
    
    def get_stats(self) -> Dict[str, float]:
        """í†µê³„ ë°˜í™˜"""
        if not self.measurements:
            return {'memory_peak': 0, 'memory_avg': 0, 'cpu_avg': 0}
        
        memories = [m['memory_mb'] for m in self.measurements]
        cpus = [m['cpu_percent'] for m in self.measurements]
        
        return {
            'memory_peak': max(memories),
            'memory_avg': np.mean(memories),
            'cpu_avg': np.mean(cpus)
        }

class AdvancedEMBenchmark:
    """ê³ ê¸‰ ì „ìê¸° í•´ì„ ë²¤ì¹˜ë§ˆí¬ ì‹œìŠ¤í…œ"""
    
    def __init__(self, output_dir: str = "benchmark_results"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # í•´ì„ê¸° ì¸í„°í˜ì´ìŠ¤
        self.solvers = {}
        self.results = []
        
        # ëª¨ë‹ˆí„°ë§
        self.monitor = ResourceMonitor()
        
        # í†µê³„ ì„¤ì •
        plt.style.use('seaborn-v0_8')
        sns.set_palette("husl")
        
        logger.info(f"ë²¤ì¹˜ë§ˆí¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ: {self.output_dir}")
    
    def register_solver(self, solver: EMSolverInterface):
        """í•´ì„ê¸° ë“±ë¡"""
        self.solvers[solver.solver_name] = solver
        logger.info(f"í•´ì„ê¸° ë“±ë¡: {solver.solver_name}")
    
    def create_test_scenarios(self) -> List[ScenarioConfig]:
        """ë‹¤ì–‘í•œ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±"""
        scenarios = [
            ScenarioConfig(
                name="simple_dipole",
                complexity="low",
                geometry_type="simple",
                frequency=2.4e9,
                dimensions=(0.5, 0.5, 0.5),
                mesh_resolution=0.02,
                expected_advantage="analytical",
                difficulty_level=2
            ),
            ScenarioConfig(
                name="patch_antenna",
                complexity="medium",
                geometry_type="moderate", 
                frequency=5.8e9,
                dimensions=(1.0, 1.0, 0.2),
                mesh_resolution=0.01,
                expected_advantage="fdtd",
                difficulty_level=4
            ),
            ScenarioConfig(
                name="antenna_array",
                complexity="high",
                geometry_type="complex",
                frequency_range=(1e9, 6e9),
                frequency_points=20,
                dimensions=(2.0, 2.0, 1.0),
                mesh_resolution=0.005,
                expected_advantage="nerf",
                difficulty_level=7
            ),
            ScenarioConfig(
                name="urban_propagation",
                complexity="extreme",
                geometry_type="urban",
                frequency=28e9,
                dimensions=(10.0, 10.0, 5.0),
                mesh_resolution=0.1,
                expected_advantage="nerf",
                difficulty_level=9
            ),
            ScenarioConfig(
                name="broadband_analysis",
                complexity="high",
                geometry_type="complex",
                frequency_range=(0.5e9, 10e9),
                frequency_points=50,
                dimensions=(1.5, 1.5, 1.0),
                mesh_resolution=0.01,
                expected_advantage="fdtd",
                difficulty_level=8
            )
        ]
        
        return scenarios
    
    def run_solver_benchmark(self, solver_name: str, scenario: ScenarioConfig, 
                           ground_truth: Optional[Dict] = None) -> BenchmarkMetrics:
        """ë‹¨ì¼ í•´ì„ê¸° ë²¤ì¹˜ë§ˆí¬"""
        solver = self.solvers[solver_name]
        
        logger.info(f"ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰: {solver_name} - {scenario.name}")
        
        # ìœ íš¨ì„± ê²€ì‚¬
        if not solver.validate_scenario(scenario):
            raise ValueError(f"{solver_name}ì—ì„œ ì‹œë‚˜ë¦¬ì˜¤ ìœ íš¨ì„± ê²€ì‚¬ ì‹¤íŒ¨")
        
        # ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œì‘
        with self.monitor.monitor():
            start_time = time.time()
            
            # ì£¼ê¸°ì  ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ ìŠ¤ë ˆë“œ ì‹œì‘
            import threading
            def monitor_resources():
                while self.monitor.monitoring:
                    self.monitor.take_measurement()
                    time.sleep(0.1)
            
            monitor_thread = threading.Thread(target=monitor_resources)
            monitor_thread.start()
            
            # í•´ì„ ì‹¤í–‰
            try:
                results = solver.solve_scenario(scenario)
                end_time = time.time()
                computation_time = end_time - start_time
                
            except Exception as e:
                logger.error(f"í•´ì„ ì‹¤íŒ¨: {solver_name} - {e}")
                raise
            finally:
                monitor_thread.join(timeout=1)
        
        # ë¦¬ì†ŒìŠ¤ í†µê³„
        resource_stats = self.monitor.get_stats()
        
        # ì •í™•ë„ ê³„ì‚°
        if ground_truth and solver_name != "OpenEMS_FDTD":
            accuracy_metrics = self._calculate_accuracy_metrics(results, ground_truth)
        else:
            # Ground truthì¸ ê²½ìš°
            accuracy_metrics = {
                'mse_error': 0.0,
                'mae_error': 0.0, 
                'relative_error': 0.0,
                'correlation_coeff': 1.0
            }
        
        # ìˆ˜ë ´ì„± ë©”íŠ¸ë¦­
        convergence_metrics = self._calculate_convergence_metrics(results, scenario)
        
        # ì£¼íŒŒìˆ˜ ì •ë³´
        if scenario.frequency:
            freq_range = (scenario.frequency, scenario.frequency)
            freq_points = 1
        elif scenario.frequency_range:
            freq_range = scenario.frequency_range
            freq_points = scenario.frequency_points
        else:
            freq_range = (0, 0)
            freq_points = 0
        
        # ë©”íŠ¸ë¦­ ê°ì²´ ìƒì„±
        metrics = BenchmarkMetrics(
            method_name=solver_name,
            scenario=scenario.name,
            
            # ì •í™•ë„
            mse_error=accuracy_metrics['mse_error'],
            mae_error=accuracy_metrics['mae_error'],
            relative_error=accuracy_metrics['relative_error'],
            correlation_coeff=accuracy_metrics['correlation_coeff'],
            
            # ì„±ëŠ¥
            computation_time=computation_time,
            memory_peak=resource_stats['memory_peak'],
            memory_average=resource_stats['memory_avg'],
            cpu_usage=resource_stats['cpu_avg'],
            
            # ìˆ˜ë ´ì„±
            convergence_iterations=convergence_metrics['iterations'],
            convergence_time=convergence_metrics['time'],
            numerical_stability=convergence_metrics['stability'],
            
            # ì£¼íŒŒìˆ˜
            frequency_range=freq_range,
            frequency_points=freq_points,
            
            # ë©”íƒ€ë°ì´í„°
            metadata={
                'scenario_config': scenario.__dict__,
                'solver_info': solver.get_solver_info(),
                'resource_measurements': len(self.monitor.measurements)
            }
        )
        
        return metrics
    
    def _calculate_accuracy_metrics(self, predicted: Dict, ground_truth: Dict) -> Dict[str, float]:
        """ì •í™•ë„ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        metrics = {}
        
        # E-field ë¹„êµ
        E_pred = predicted['E_field']
        E_true = ground_truth['E_field']
        
        # MSE
        mse_e = np.mean(np.abs(E_pred - E_true)**2)
        
        # MAE  
        mae_e = np.mean(np.abs(E_pred - E_true))
        
        # ìƒëŒ€ ì˜¤ì°¨
        rel_e = np.mean(np.abs(E_pred - E_true) / (np.abs(E_true) + 1e-10))
        
        # ìƒê´€ê³„ìˆ˜
        E_pred_flat = E_pred.real.flatten()
        E_true_flat = E_true.real.flatten()
        corr_e = np.corrcoef(E_pred_flat, E_true_flat)[0, 1]
        
        metrics = {
            'mse_error': float(mse_e),
            'mae_error': float(mae_e),
            'relative_error': float(rel_e),
            'correlation_coeff': float(corr_e) if not np.isnan(corr_e) else 0.0
        }
        
        return metrics
    
    def _calculate_convergence_metrics(self, results: Dict, scenario: ScenarioConfig) -> Dict[str, float]:
        """ìˆ˜ë ´ì„± ë©”íŠ¸ë¦­ ê³„ì‚°"""
        iterations = results.get('convergence_iterations', 0)
        
        # ìˆ˜ë ´ ì‹œê°„ (ì „ì²´ ê³„ì‚° ì‹œê°„ì˜ ë¹„ìœ¨ë¡œ ì¶”ì •)
        convergence_time = 0.0  # ì‹¤ì œë¡œëŠ” ìˆ˜ë ´ ê³¼ì • ëª¨ë‹ˆí„°ë§ í•„ìš”
        
        # ìˆ˜ì¹˜ì  ì•ˆì •ì„± (ê²°ê³¼ì˜ ë³€ë™ì„±ìœ¼ë¡œ ì¶”ì •)
        E_field = results.get('E_field', np.array([0]))
        stability = 1.0 / (1.0 + np.std(np.abs(E_field)))
        
        return {
            'iterations': iterations,
            'time': convergence_time,
            'stability': float(stability)
        }
    
    def run_comprehensive_benchmark(self, parallel: bool = False) -> List[BenchmarkMetrics]:
        """ì¢…í•© ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        logger.info("ğŸš€ ì¢…í•© ì „ìê¸° í•´ì„ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘!")
        logger.info("=" * 60)
        
        scenarios = self.create_test_scenarios()
        all_results = []
        
        for scenario in scenarios:
            logger.info(f"\nğŸ“‹ ì‹œë‚˜ë¦¬ì˜¤: {scenario.name}")
            logger.info(f"   ë³µì¡ë„: {scenario.complexity}")
            logger.info(f"   ë‚œì´ë„: {scenario.difficulty_level}/10")
            logger.info("-" * 40)
            
            # Ground Truth ìƒì„± (FDTD)
            if "OpenEMS_FDTD" in self.solvers:
                fdtd_metrics = self.run_solver_benchmark("OpenEMS_FDTD", scenario)
                all_results.append(fdtd_metrics)
                
                # Ground Truth ê²°ê³¼ ì €ì¥
                fdtd_solver = self.solvers["OpenEMS_FDTD"]
                ground_truth = fdtd_solver.solve_scenario(scenario)
            else:
                ground_truth = None
                logger.warning("FDTD í•´ì„ê¸°ê°€ ì—†ì–´ Ground Truth ìƒì„± ë¶ˆê°€")
            
            # ë‹¤ë¥¸ í•´ì„ê¸°ë“¤ í…ŒìŠ¤íŠ¸
            other_solvers = [name for name in self.solvers.keys() if name != "OpenEMS_FDTD"]
            
            if parallel:
                # ë³‘ë ¬ ì‹¤í–‰
                with ThreadPoolExecutor(max_workers=len(other_solvers)) as executor:
                    futures = []
                    for solver_name in other_solvers:
                        future = executor.submit(
                            self.run_solver_benchmark, 
                            solver_name, scenario, ground_truth
                        )
                        futures.append(future)
                    
                    for future in futures:
                        try:
                            metrics = future.result(timeout=300)  # 5ë¶„ íƒ€ì„ì•„ì›ƒ
                            all_results.append(metrics)
                        except Exception as e:
                            logger.error(f"ë³‘ë ¬ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            else:
                # ìˆœì°¨ ì‹¤í–‰
                for solver_name in other_solvers:
                    try:
                        metrics = self.run_solver_benchmark(solver_name, scenario, ground_truth)
                        all_results.append(metrics)
                    except Exception as e:
                        logger.error(f"í•´ì„ê¸° {solver_name} ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            
            # ì‹œë‚˜ë¦¬ì˜¤ë³„ ê²°ê³¼ ì¶œë ¥
            self._print_scenario_results(scenario.name, all_results)
        
        # ê²°ê³¼ ì €ì¥
        self.results = all_results
        self._save_results()
        
        # ì¢…í•© ë¶„ì„
        self._analyze_overall_performance()
        self._generate_comprehensive_plots()
        
        return all_results
    
    def _print_scenario_results(self, scenario_name: str, all_results: List[BenchmarkMetrics]):
        """ì‹œë‚˜ë¦¬ì˜¤ë³„ ê²°ê³¼ ì¶œë ¥"""
        scenario_results = [r for r in all_results if r.scenario == scenario_name]
        
        if not scenario_results:
            return
        
        print(f"\nğŸ“Š {scenario_name} ê²°ê³¼:")
        print("=" * 70)
        
        # í…Œì´ë¸” í˜•íƒœë¡œ ì¶œë ¥
        headers = ["ë°©ë²•", "ì •í™•ë„", "íš¨ìœ¨ì„±", "ì‹œê°„(s)", "ë©”ëª¨ë¦¬(MB)", "ìƒê´€ê³„ìˆ˜"]
        print(f"{'':15s} {'ì •í™•ë„':>8s} {'íš¨ìœ¨ì„±':>8s} {'ì‹œê°„(s)':>10s} {'ë©”ëª¨ë¦¬(MB)':>12s} {'ìƒê´€ê³„ìˆ˜':>10s}")
        print("-" * 70)
        
        for result in scenario_results:
            print(f"{result.method_name:15s} "
                  f"{result.accuracy_score:8.4f} "
                  f"{result.efficiency_score:8.4f} "
                  f"{result.computation_time:10.3f} "
                  f"{result.memory_peak:12.1f} "
                  f"{result.correlation_coeff:10.4f}")
        
        # ìµœê³  ì„±ëŠ¥ ë°©ë²• ì°¾ê¸°
        if len(scenario_results) > 1:
            best_accuracy = max(scenario_results, key=lambda x: x.accuracy_score)
            best_speed = min(scenario_results, key=lambda x: x.computation_time)
            best_efficiency = max(scenario_results, key=lambda x: x.efficiency_score)
            
            print(f"\nğŸ† ìµœê³  ì •í™•ë„: {best_accuracy.method_name} ({best_accuracy.accuracy_score:.4f})")
            print(f"âš¡ ìµœê³  ì†ë„:   {best_speed.method_name} ({best_speed.computation_time:.3f}ì´ˆ)")
            print(f"ğŸ¯ ìµœê³  íš¨ìœ¨ì„±: {best_efficiency.method_name} ({best_efficiency.efficiency_score:.4f})")
    
    def _analyze_overall_performance(self):
        """ì¢…í•© ì„±ëŠ¥ ë¶„ì„"""
        print("\n" + "="*70)
        print("ğŸ“ˆ ì¢…í•© ì„±ëŠ¥ ë¶„ì„ ë° ê¶Œì¥ì‚¬í•­")
        print("="*70)
        
        methods = list(set([r.method_name for r in self.results]))
        
        # ë°©ë²•ë³„ í†µê³„ ê³„ì‚°
        method_stats = {}
        for method in methods:
            method_results = [r for r in self.results if r.method_name == method]
            
            if method_results:
                stats = {
                    'avg_accuracy': np.mean([r.accuracy_score for r in method_results]),
                    'std_accuracy': np.std([r.accuracy_score for r in method_results]),
                    'avg_time': np.mean([r.computation_time for r in method_results]),
                    'std_time': np.std([r.computation_time for r in method_results]),
                    'avg_memory': np.mean([r.memory_peak for r in method_results]),
                    'avg_efficiency': np.mean([r.efficiency_score for r in method_results]),
                    'reliability': np.mean([r.numerical_stability for r in method_results])
                }
                method_stats[method] = stats
        
        # ë°©ë²•ë³„ ìƒì„¸ ë¶„ì„
        for method, stats in method_stats.items():
            print(f"\nğŸ”¹ {method}")
            print(f"   í‰ê·  ì •í™•ë„: {stats['avg_accuracy']:.4f} Â± {stats['std_accuracy']:.4f}")
            print(f"   í‰ê·  ì‹œê°„:   {stats['avg_time']:.3f}ì´ˆ Â± {stats['std_time']:.3f}")
            print(f"   í‰ê·  ë©”ëª¨ë¦¬: {stats['avg_memory']:.1f}MB")
            print(f"   íš¨ìœ¨ì„±:     {stats['avg_efficiency']:.4f}")
            print(f"   ì•ˆì •ì„±:     {stats['reliability']:.4f}")
            
            # ë°©ë²•ë³„ ê¶Œì¥ì‚¬í•­
            self._generate_method_recommendations(method, stats)
        
        # ì‹œë‚˜ë¦¬ì˜¤ë³„ ìµœì  ë°©ë²• ì¶”ì²œ
        self._recommend_optimal_methods()
        
        # í†µê³„ì  ìœ ì˜ì„± ê²€ì¦
        self._perform_statistical_tests()
    
    def _generate_method_recommendations(self, method: str, stats: Dict):
        """ë°©ë²•ë³„ ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        if method == "EM-NeRF":
            if stats['avg_accuracy'] > 0.9 and stats['avg_time'] < 1.0:
                print("   âœ… ì¶”ì²œ: ì‹¤ì‹œê°„ ì˜ˆì¸¡, ëŒ€í™”í˜• ì„¤ê³„, ë³µì¡í•œ í™˜ê²½ ëª¨ë¸ë§")
            elif stats['avg_accuracy'] > 0.8:
                print("   âœ… ì¶”ì²œ: ë¹ ë¥¸ ê·¼ì‚¬ í•´ì„, ì´ˆê¸° ì„¤ê³„ ê²€í† ")
            else:
                print("   âš ï¸  ê°œì„  í•„ìš”: ë” ë§ì€ í›ˆë ¨ ë°ì´í„°, ëª¨ë¸ ì•„í‚¤í…ì²˜ ê°œì„ ")
            
            if stats['avg_time'] < 0.5:
                print("   ğŸ’¡ ì¥ì : ë§¤ìš° ë¹ ë¥¸ ì¶”ë¡  ì†ë„ë¡œ ë°˜ë³µ ì„¤ê³„ì— ì í•©")
            
        elif method == "OpenEMS_FDTD":
            print("   âœ… ì¶”ì²œ: ì •í™•í•œ í•´ì„, ê´‘ëŒ€ì—­ ë¶„ì„, ë³µì¡í•œ ê¸°í•˜êµ¬ì¡°")
            if stats['avg_time'] > 10:
                print("   âš ï¸  ë‹¨ì : ê¸´ ê³„ì‚° ì‹œê°„, ê³ ì„±ëŠ¥ ì»´í“¨íŒ… í™˜ê²½ í•„ìš”")
            print("   ğŸ’¡ ì¥ì : ê°€ì¥ ì •í™•í•˜ê³  ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ê²°ê³¼")
            
        elif method == "Method_of_Moments":
            if stats['avg_accuracy'] > 0.85 and stats['avg_time'] < 5:
                print("   âœ… ì¶”ì²œ: ì•ˆí…Œë‚˜ ì„¤ê³„, ì¤‘ê°„ ë³µì¡ë„ ë¬¸ì œ")
            else:
                print("   âš ï¸  ì œí•œ: ë³µì¡í•œ êµ¬ì¡°ë‚˜ ëŒ€ê·œëª¨ ë¬¸ì œì—ëŠ” ë¶€ì í•©")
            print("   ğŸ’¡ ì¥ì : ì£¼íŒŒìˆ˜ ì˜ì—­ í•´ì„, ì „ë„ì„± êµ¬ì¡° íŠ¹í™”")
    
    def _recommend_optimal_methods(self):
        """ì‹œë‚˜ë¦¬ì˜¤ë³„ ìµœì  ë°©ë²• ì¶”ì²œ"""
        print(f"\nğŸ¯ ì‹œë‚˜ë¦¬ì˜¤ë³„ ìµœì  ë°©ë²• ì¶”ì²œ")
        print("-" * 50)
        
        scenarios = list(set([r.scenario for r in self.results]))
        
        for scenario in scenarios:
            scenario_results = [r for r in self.results if r.scenario == scenario]
            
            if len(scenario_results) < 2:
                continue
            
            # ë‹¤ì–‘í•œ ê¸°ì¤€ìœ¼ë¡œ ìµœì  ë°©ë²• ì„ íƒ
            best_accuracy = max(scenario_results, key=lambda x: x.accuracy_score)
            best_speed = min(scenario_results, key=lambda x: x.computation_time)
            best_balanced = max(scenario_results, key=lambda x: (x.accuracy_score + x.efficiency_score) / 2)
            
            print(f"\nğŸ“‹ {scenario}:")
            print(f"   ì •í™•ë„ ìš°ì„ : {best_accuracy.method_name} (ì •í™•ë„: {best_accuracy.accuracy_score:.3f})")
            print(f"   ì†ë„ ìš°ì„ :   {best_speed.method_name} (ì‹œê°„: {best_speed.computation_time:.3f}s)")
            print(f"   ê· í˜• ìµœì :   {best_balanced.method_name} (ì¢…í•©ì ìˆ˜: {(best_balanced.accuracy_score + best_balanced.efficiency_score)/2:.3f})")
    
    def _perform_statistical_tests(self):
        """í†µê³„ì  ìœ ì˜ì„± ê²€ì¦"""
        print(f"\nğŸ“Š í†µê³„ì  ìœ ì˜ì„± ê²€ì¦")
        print("-" * 40)
        
        methods = list(set([r.method_name for r in self.results]))
        
        if len(methods) < 2:
            print("ë¹„êµí•  ë°©ë²•ì´ ë¶€ì¡±í•©ë‹ˆë‹¤.")
            return
        
        # ì •í™•ë„ ë¹„êµ (paired t-test)
        for i, method1 in enumerate(methods):
            for method2 in methods[i+1:]:
                acc1 = [r.accuracy_score for r in self.results if r.method_name == method1]
                acc2 = [r.accuracy_score for r in self.results if r.method_name == method2]
                
                if len(acc1) == len(acc2) and len(acc1) > 1:
                    statistic, p_value = stats.ttest_rel(acc1, acc2)
                    significance = "ìœ ì˜í•¨" if p_value < 0.05 else "ìœ ì˜í•˜ì§€ ì•ŠìŒ"
                    
                    print(f"{method1} vs {method2}:")
                    print(f"   ì •í™•ë„ ì°¨ì´: {significance} (p={p_value:.4f})")
    
    def _save_results(self):
        """ê²°ê³¼ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # JSON í˜•íƒœë¡œ ì €ì¥
        results_as_list = []
        for result in self.results:
            result_dict = {
                'method_name': result.method_name,
                'scenario': result.scenario,
                'accuracy_score': result.accuracy_score,
                'efficiency_score': result.efficiency_score,
                'computation_time': result.computation_time,
                'memory_peak': result.memory_peak,
                'mse_error': result.mse_error,
                'correlation_coeff': result.correlation_coeff,
                'timestamp': result.timestamp,
                'metadata': result.metadata
            }
            results_as_list.append(result_dict)
        
        # JSON ì €ì¥
        json_file = self.output_dir / f"benchmark_results_{timestamp}.json"
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(results_as_list, f, indent=2, ensure_ascii=False)
        
        # Pickle ì €ì¥ (ê°ì²´ ì „ì²´)
        pickle_file = self.output_dir / f"benchmark_objects_{timestamp}.pkl"
        with open(pickle_file, 'wb') as f:
            pickle.dump(self.results, f)
        
        # CSV ì €ì¥ (pandas DataFrame)
        df = pd.DataFrame(results_as_list)
        csv_file = self.output_dir / f"benchmark_results_{timestamp}.csv"
        df.to_csv(csv_file, index=False, encoding='utf-8')
        
        logger.info(f"ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {json_file}, {pickle_file}, {csv_file}")
    
    def _generate_comprehensive_plots(self):
        """í¬ê´„ì ì¸ ì‹œê°í™” ìƒì„±"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. ì¢…í•© ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ
        self._plot_performance_dashboard(timestamp)
        
        # 2. ìƒì„¸ ë¶„ì„ í”Œë¡¯ë“¤
        self._plot_accuracy_comparison(timestamp)
        self._plot_efficiency_analysis(timestamp)
        self._plot_scalability_analysis(timestamp)
        self._plot_method_radar_chart(timestamp)
        
        logger.info(f"ëª¨ë“  í”Œë¡¯ ìƒì„± ì™„ë£Œ: {self.output_dir}")
    
    def _plot_performance_dashboard(self, timestamp: str):
        """ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ"""
        fig = plt.figure(figsize=(20, 15))
        gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)
        
        methods = list(set([r.method_name for r in self.results]))
        scenarios = list(set([r.scenario for r in self.results]))
        
        # ìƒ‰ìƒ íŒ”ë ˆíŠ¸
        colors = plt.cm.Set3(np.linspace(0, 1, len(methods)))
        method_colors = dict(zip(methods, colors))
        
        # 1. ì •í™•ë„ íˆíŠ¸ë§µ
        ax1 = fig.add_subplot(gs[0, 0])
        accuracy_matrix = np.zeros((len(methods), len(scenarios)))
        
        for i, method in enumerate(methods):
            for j, scenario in enumerate(scenarios):
                results = [r for r in self.results if r.method_name == method and r.scenario == scenario]
                if results:
                    accuracy_matrix[i, j] = results[0].accuracy_score
        
        im1 = ax1.imshow(accuracy_matrix, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)
        ax1.set_xticks(range(len(scenarios)))
        ax1.set_xticklabels(scenarios, rotation=45, ha='right')
        ax1.set_yticks(range(len(methods)))
        ax1.set_yticklabels(methods)
        ax1.set_title('ì •í™•ë„ íˆíŠ¸ë§µ', fontweight='bold')
        plt.colorbar(im1, ax=ax1, shrink=0.8)
        
        # 2. ê³„ì‚° ì‹œê°„ ë¹„êµ
        ax2 = fig.add_subplot(gs[0, 1])
        time_data = {}
        for method in methods:
            method_results = [r for r in self.results if r.method_name == method]
            time_data[method] = [r.computation_time for r in method_results]
        
        bp = ax2.boxplot([time_data[method] for method in methods], 
                        labels=methods, patch_artist=True)
        for patch, color in zip(bp['boxes'], colors):
            patch.set_facecolor(color)
        ax2.set_ylabel('ê³„ì‚° ì‹œê°„ (ì´ˆ)')
        ax2.set_title('ê³„ì‚° ì‹œê°„ ë¶„í¬', fontweight='bold')
        ax2.set_yscale('log')
        plt.setp(ax2.get_xticklabels(), rotation=45, ha='right')
        
        # 3. íš¨ìœ¨ì„± ì ìˆ˜ ë¶„í¬
        ax3 = fig.add_subplot(gs[0, 2])
        efficiency_data = {}
        for method in methods:
            method_results = [r for r in self.results if r.method_name == method]
            efficiency_data[method] = [r.efficiency_score for r in method_results]
        
        bp = ax3.boxplot([efficiency_data[method] for method in methods],
                        labels=methods, patch_artist=True)
        
        for patch, color in zip(bp['boxes'], colors):
            patch.set_facecolor(color)
        
        ax3.set_ylabel('íš¨ìœ¨ì„± ì ìˆ˜')
        ax3.set_title('íš¨ìœ¨ì„± ì ìˆ˜ ë¶„í¬', fontweight='bold')
        plt.setp(ax3.get_xticklabels(), rotation=45, ha='right')
        ax3.grid(True, alpha=0.3)
        
        # 4. CPU ì‚¬ìš©ë¥  ë¶„ì„
        ax4 = fig.add_subplot(gs[1, 0])
        cpu_data = {}
        for method in methods:
            method_results = [r for r in self.results if r.method_name == method]
            cpu_data[method] = [r.cpu_usage for r in method_results]
        
        bp2 = ax4.boxplot([cpu_data[method] for method in methods],
                         labels=methods, patch_artist=True)
        
        for patch, color in zip(bp2['boxes'], colors):
            patch.set_facecolor(color)
        
        ax4.set_ylabel('CPU ì‚¬ìš©ë¥  (%)')
        ax4.set_title('CPU ì‚¬ìš©ë¥  ë¶„í¬', fontweight='bold')
        plt.setp(ax4.get_xticklabels(), rotation=45, ha='right')
        ax4.grid(True, alpha=0.3)
        
        # 5. ì‹œë‚˜ë¦¬ì˜¤ë³„ ì„±ëŠ¥ ìˆœìœ„
        ax5 = fig.add_subplot(gs[1, 1])
        scenario_rankings = {}
        
        for scenario in scenarios:
            scenario_results = [r for r in self.results if r.scenario == scenario]
            # ì¢…í•© ì ìˆ˜ë¡œ ìˆœìœ„ ë§¤ê¸°ê¸°
            sorted_results = sorted(scenario_results, 
                                  key=lambda x: (x.accuracy_score + x.efficiency_score) / 2, 
                                  reverse=True)
            
            for rank, result in enumerate(sorted_results):
                if result.method_name not in scenario_rankings:
                    scenario_rankings[result.method_name] = []
                scenario_rankings[result.method_name].append(rank + 1)
        
        # í‰ê·  ìˆœìœ„ ê³„ì‚°
        avg_ranks = {}
        for method, ranks in scenario_rankings.items():
            avg_ranks[method] = np.mean(ranks)
        
        sorted_methods = sorted(avg_ranks.keys(), key=lambda x: avg_ranks[x])
        ranks = [avg_ranks[method] for method in sorted_methods]
        
        bars = ax5.barh(sorted_methods, ranks, color=[method_colors[m] for m in sorted_methods])
        ax5.set_xlabel('í‰ê·  ìˆœìœ„')
        ax5.set_title('ì¢…í•© ì„±ëŠ¥ ìˆœìœ„', fontweight='bold')
        ax5.invert_yaxis()
        
        # 6. ë³µì¡ë„ë³„ ì„±ëŠ¥ íŠ¸ë Œë“œ
        ax6 = fig.add_subplot(gs[1, 2])
        complexity_order = ['low', 'medium', 'high', 'extreme']
        
        for method in methods:
            complexity_scores = []
            for complexity in complexity_order:
                # ë³µì¡ë„ë³„ í‰ê·  ì •í™•ë„
                complex_results = [r for r in self.results 
                                 if r.method_name == method and 
                                 complexity in r.metadata.get('scenario_config', {}).get('complexity', '')]
                if complex_results:
                    avg_score = np.mean([r.accuracy_score for r in complex_results])
                    complexity_scores.append(avg_score)
                else:
                    complexity_scores.append(np.nan)
            
            # NaNì´ ì•„ë‹Œ ê°’ë“¤ë§Œ í”Œë¡¯
            valid_indices = [i for i, score in enumerate(complexity_scores) if not np.isnan(score)]
            valid_complexities = [complexity_order[i] for i in valid_indices]
            valid_scores = [complexity_scores[i] for i in valid_indices]
            
            if valid_scores:
                ax6.plot(valid_complexities, valid_scores, 
                        marker='o', linewidth=2, markersize=8,
                        label=method, color=method_colors[method])
        
        ax6.set_xlabel('ì‹œë‚˜ë¦¬ì˜¤ ë³µì¡ë„')
        ax6.set_ylabel('ì •í™•ë„ ì ìˆ˜')
        ax6.set_title('ë³µì¡ë„ë³„ ì„±ëŠ¥ íŠ¸ë Œë“œ', fontweight='bold')
        ax6.legend()
        ax6.grid(True, alpha=0.3)
        
        # 7. ìˆ˜ë ´ì„± ë¶„ì„
        ax7 = fig.add_subplot(gs[2, 0])
        convergence_data = {}
        for method in methods:
            method_results = [r for r in self.results if r.method_name == method]
            convergence_data[method] = [r.convergence_iterations for r in method_results]
        
        x_pos = np.arange(len(methods))
        means = [np.mean(convergence_data[method]) for method in methods]
        stds = [np.std(convergence_data[method]) for method in methods]
        
        bars = ax7.bar(x_pos, means, yerr=stds, capsize=5,
                      color=[method_colors[m] for m in methods], alpha=0.7)
        ax7.set_xlabel('ë°©ë²•')
        ax7.set_ylabel('ìˆ˜ë ´ ë°˜ë³µ íšŸìˆ˜')
        ax7.set_title('ìˆ˜ë ´ì„± ë¹„êµ', fontweight='bold')
        ax7.set_xticks(x_pos)
        ax7.set_xticklabels(methods, rotation=45, ha='right')
        
        # 8. ìƒê´€ê³„ìˆ˜ ë¶„í¬
        ax8 = fig.add_subplot(gs[2, 1])
        for method in methods:
            method_results = [r for r in self.results if r.method_name == method 
                            and r.method_name != "OpenEMS_FDTD"]  # Ground truth ì œì™¸
            if method_results:
                correlations = [r.correlation_coeff for r in method_results]
                ax8.hist(correlations, alpha=0.6, label=method, bins=10,
                        color=method_colors[method])
        
        ax8.set_xlabel('ìƒê´€ê³„ìˆ˜')
        ax8.set_ylabel('ë¹ˆë„')
        ax8.set_title('Ground Truthì™€ì˜ ìƒê´€ê´€ê³„', fontweight='bold')
        ax8.legend()
        ax8.grid(True, alpha=0.3)
        
        # 9. ì¢…í•© ì„±ëŠ¥ ìŠ¤ì½”ì–´
        ax9 = fig.add_subplot(gs[2, 2])
        overall_scores = {}
        for method in methods:
            method_results = [r for r in self.results if r.method_name == method]
            if method_results:
                # ì •í™•ë„, íš¨ìœ¨ì„±, ì•ˆì •ì„±ì˜ ê°€ì¤‘ í‰ê· 
                accuracy = np.mean([r.accuracy_score for r in method_results])
                efficiency = np.mean([r.efficiency_score for r in method_results])
                stability = np.mean([r.numerical_stability for r in method_results])
                
                overall_score = 0.4 * accuracy + 0.4 * efficiency + 0.2 * stability
                overall_scores[method] = overall_score
        
        sorted_methods = sorted(overall_scores.keys(), key=lambda x: overall_scores[x], reverse=True)
        scores = [overall_scores[method] for method in sorted_methods]
        
        bars = ax9.bar(sorted_methods, scores, 
                      color=[method_colors[m] for m in sorted_methods])
        ax9.set_ylabel('ì¢…í•© ì„±ëŠ¥ ì ìˆ˜')
        ax9.set_title('ì¢…í•© ì„±ëŠ¥ í‰ê°€', fontweight='bold')
        plt.setp(ax9.get_xticklabels(), rotation=45, ha='right')
        
        # ê° ë°”ì— ì ìˆ˜ í‘œì‹œ
        for bar, score in zip(bars, scores):
            height = bar.get_height()
            ax9.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                    f'{score:.3f}', ha='center', va='bottom', fontweight='bold')
        
        plt.suptitle('ì „ìê¸° í•´ì„ ë°©ë²• ì¢…í•© ì„±ëŠ¥ ëŒ€ì‹œë³´ë“œ', 
                    fontsize=16, fontweight='bold', y=0.98)
        
        # ì €ì¥
        dashboard_file = self.output_dir / f"performance_dashboard_{timestamp}.png"
        plt.savefig(dashboard_file, dpi=300, bbox_inches='tight', facecolor='white')
        plt.show()
    
    def _plot_accuracy_comparison(self, timestamp: str):
        """ì •í™•ë„ ìƒì„¸ ë¹„êµ"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        
        methods = [m for m in set([r.method_name for r in self.results]) if m != "OpenEMS_FDTD"]
        scenarios = list(set([r.scenario for r in self.results]))
        
        # 1. MSE ë¹„êµ
        mse_data = {method: [] for method in methods}
        scenario_labels = []
        
        for scenario in scenarios:
            scenario_labels.append(scenario)
            for method in methods:
                results = [r for r in self.results if r.method_name == method and r.scenario == scenario]
                if results:
                    mse_data[method].append(results[0].mse_error)
                else:
                    mse_data[method].append(np.nan)
        
        x = np.arange(len(scenarios))
        width = 0.35
        
        for i, (method, mses) in enumerate(mse_data.items()):
            ax1.bar(x + i*width, mses, width, label=method, alpha=0.8)
        
        ax1.set_xlabel('ì‹œë‚˜ë¦¬ì˜¤')
        ax1.set_ylabel('MSE ì˜¤ì°¨')
        ax1.set_title('MSE ì˜¤ì°¨ ë¹„êµ', fontweight='bold')
        ax1.set_yscale('log')
        ax1.set_xticks(x + width/2)
        ax1.set_xticklabels(scenario_labels, rotation=45, ha='right')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. ìƒëŒ€ ì˜¤ì°¨ ë¹„êµ
        rel_data = {method: [] for method in methods}
        
        for scenario in scenarios:
            for method in methods:
                results = [r for r in self.results if r.method_name == method and r.scenario == scenario]
                if results:
                    rel_data[method].append(results[0].relative_error * 100)  # í¼ì„¼íŠ¸
                else:
                    rel_data[method].append(np.nan)
        
        for i, (method, rels) in enumerate(rel_data.items()):
            ax2.bar(x + i*width, rels, width, label=method, alpha=0.8)
        
        ax2.set_xlabel('ì‹œë‚˜ë¦¬ì˜¤')
        ax2.set_ylabel('ìƒëŒ€ ì˜¤ì°¨ (%)')
        ax2.set_title('ìƒëŒ€ ì˜¤ì°¨ ë¹„êµ', fontweight='bold')
        ax2.set_xticks(x + width/2)
        ax2.set_xticklabels(scenario_labels, rotation=45, ha='right')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. ìƒê´€ê³„ìˆ˜ ë¶„í¬
        for method in methods:
            method_results = [r for r in self.results if r.method_name == method]
            correlations = [r.correlation_coeff for r in method_results if not np.isnan(r.correlation_coeff)]
            
            if correlations:
                ax3.hist(correlations, alpha=0.6, label=method, bins=15)
        
        ax3.set_xlabel('ìƒê´€ê³„ìˆ˜')
        ax3.set_ylabel('ë¹ˆë„')
        ax3.set_title('Ground Truthì™€ì˜ ìƒê´€ê´€ê³„ ë¶„í¬', fontweight='bold')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 4. ì •í™•ë„ ê°œì„  íŠ¸ë Œë“œ (ì‹œë‚˜ë¦¬ì˜¤ ë³µì¡ë„ë³„)
        complexity_order = ['low', 'medium', 'high', 'extreme']
        
        for method in methods:
            accuracy_trend = []
            for complexity in complexity_order:
                complex_results = [r for r in self.results 
                                 if r.method_name == method and 
                                 complexity in r.metadata.get('scenario_config', {}).get('complexity', '')]
                if complex_results:
                    avg_accuracy = np.mean([r.accuracy_score for r in complex_results])
                    accuracy_trend.append(avg_accuracy)
                else:
                    accuracy_trend.append(np.nan)
            
            # NaNì´ ì•„ë‹Œ ê°’ë“¤ë§Œ í”Œë¡¯
            valid_indices = [i for i, acc in enumerate(accuracy_trend) if not np.isnan(acc)]
            if valid_indices:
                valid_complexities = [complexity_order[i] for i in valid_indices]
                valid_accuracies = [accuracy_trend[i] for i in valid_indices]
                
                ax4.plot(valid_complexities, valid_accuracies, 
                        marker='o', linewidth=2, markersize=8, label=method)
        
        ax4.set_xlabel('ì‹œë‚˜ë¦¬ì˜¤ ë³µì¡ë„')
        ax4.set_ylabel('ì •í™•ë„ ì ìˆ˜')
        ax4.set_title('ë³µì¡ë„ë³„ ì •í™•ë„ íŠ¸ë Œë“œ', fontweight='bold')
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        accuracy_file = self.output_dir / f"accuracy_analysis_{timestamp}.png"
        plt.savefig(accuracy_file, dpi=300, bbox_inches='tight')
        plt.show()
    
    def _plot_efficiency_analysis(self, timestamp: str):
        """íš¨ìœ¨ì„± ë¶„ì„ í”Œë¡¯"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        
        methods = list(set([r.method_name for r in self.results]))
        
        # 1. ì‹œê°„ vs ì •í™•ë„ íŠ¸ë ˆì´ë“œì˜¤í”„
        for method in methods:
            method_results = [r for r in self.results if r.method_name == method]
            times = [r.computation_time for r in method_results]
            accuracies = [r.accuracy_score for r in method_results]
            
            ax1.scatter(times, accuracies, label=method, s=100, alpha=0.7)
        
        ax1.set_xlabel('ê³„ì‚° ì‹œê°„ (ì´ˆ)')
        ax1.set_ylabel('ì •í™•ë„ ì ìˆ˜')
        ax1.set_title('ì‹œê°„ vs ì •í™•ë„ íŠ¸ë ˆì´ë“œì˜¤í”„', fontweight='bold')
        ax1.set_xscale('log')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
        for method in methods:
            method_results = [r for r in self.results if r.method_name == method]
            memories = [r.memory_peak for r in method_results]
            accuracies = [r.accuracy_score for r in method_results]
            
            ax2.scatter(memories, accuracies, label=method, s=100, alpha=0.7)
        
        ax2.set_xlabel('ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)')
        ax2.set_ylabel('ì •í™•ë„ ì ìˆ˜')
        ax2.set_title('ë©”ëª¨ë¦¬ vs ì •í™•ë„', fontweight='bold')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. íš¨ìœ¨ì„± ì ìˆ˜ ë¶„í¬
        efficiency_data = {}
        for method in methods:
            method_results = [r for r in self.results if r.method_name == method]
            efficiency_data[method] = [r.efficiency_score for r in method_results]
        
        bp = ax3.boxplot([efficiency_data[method] for method in methods],
                        labels=methods, patch_artist=True)
        
        colors = plt.cm.Set3(np.linspace(0, 1, len(methods)))
        for patch, color in zip(bp['boxes'], colors):
            patch.set_facecolor(color)
        
        ax3.set_ylabel('íš¨ìœ¨ì„± ì ìˆ˜')
        ax3.set_title('íš¨ìœ¨ì„± ì ìˆ˜ ë¶„í¬', fontweight='bold')
        plt.setp(ax3.get_xticklabels(), rotation=45, ha='right')
        ax3.grid(True, alpha=0.3)
        
        # 4. CPU ì‚¬ìš©ë¥  ë¶„ì„
        cpu_data = {}
        for method in methods:
            method_results = [r for r in self.results if r.method_name == method]
            cpu_data[method] = [r.cpu_usage for r in method_results]
        
        bp2 = ax4.boxplot([cpu_data[method] for method in methods],
                         labels=methods, patch_artist=True)
        
        for patch, color in zip(bp2['boxes'], colors):
            patch.set_facecolor(color)
        
        ax4.set_ylabel('CPU ì‚¬ìš©ë¥  (%)')
        ax4.set_title('CPU ì‚¬ìš©ë¥  ë¶„í¬', fontweight='bold')
        plt.setp(ax4.get_xticklabels(), rotation=45, ha='right')
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        efficiency_file = self.output_dir / f"efficiency_analysis_{timestamp}.png"
        plt.savefig(efficiency_file, dpi=300, bbox_inches='tight')
        plt.show()
    
    def _plot_scalability_analysis(self, timestamp: str):
        """í™•ì¥ì„± ë¶„ì„"""
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))
        
        methods = list(set([r.method_name for r in self.results]))
        
        # 1. ë¬¸ì œ í¬ê¸°ë³„ ì„±ëŠ¥ (ì‹œë‚˜ë¦¬ì˜¤ ë³µì¡ë„ë¡œ ëŒ€ì²´)
        complexity_mapping = {'low': 1, 'medium': 2, 'high': 3, 'extreme': 4}
        
        for method in methods:
            complexities = []
            times = []
            
            for result in self.results:
                if result.method_name == method:
                    complexity = result.metadata.get('scenario_config', {}).get('complexity', 'medium')
                    complexity_level = complexity_mapping.get(complexity, 2)
                    complexities.append(complexity_level)
                    times.append(result.computation_time)
            
            if complexities and times:
                ax1.scatter(complexities, times, label=method, s=100, alpha=0.7)
                
                # ì¶”ì„¸ì„  ì¶”ê°€
                if len(complexities) > 2:
                    z = np.polyfit(complexities, times, 1)
                    p = np.poly1d(z)
                    x_trend = np.linspace(min(complexities), max(complexities), 100)
                    ax1.plot(x_trend, p(x_trend), "--", alpha=0.5)
        
        ax1.set_xlabel('ë¬¸ì œ ë³µì¡ë„')
        ax1.set_ylabel('ê³„ì‚° ì‹œê°„ (ì´ˆ)')
        ax1.set_title('ë¬¸ì œ í¬ê¸°ë³„ ê³„ì‚° ì‹œê°„ í™•ì¥ì„±', fontweight='bold')
        ax1.set_yscale('log')
        ax1.set_xticks([1, 2, 3, 4])
        ax1.set_xticklabels(['Low', 'Medium', 'High', 'Extreme'])
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # 2. ë©”ëª¨ë¦¬ í™•ì¥ì„±
        for method in methods:
            complexities = []
            memories = []
            
            for result in self.results:
                if result.method_name == method:
                    complexity = result.metadata.get('scenario_config', {}).get('complexity', 'medium')
                    complexity_level = complexity_mapping.get(complexity, 2)
                    complexities.append(complexity_level)
                    memories.append(result.memory_peak)
            
            if complexities and memories:
                ax2.scatter(complexities, memories, label=method, s=100, alpha=0.7)
                
                # ì¶”ì„¸ì„  ì¶”ê°€
                if len(complexities) > 2:
                    z = np.polyfit(complexities, memories, 1)
                    p = np.poly1d(z)
                    x_trend = np.linspace(min(complexities), max(complexities), 100)
                    ax2.plot(x_trend, p(x_trend), "--", alpha=0.5)
        
        ax2.set_xlabel('ë¬¸ì œ ë³µì¡ë„')
        ax2.set_ylabel('ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)')
        ax2.set_title('ë¬¸ì œ í¬ê¸°ë³„ ë©”ëª¨ë¦¬ í™•ì¥ì„±', fontweight='bold')
        ax2.set_xticks([1, 2, 3, 4])
        ax2.set_xticklabels(['Low', 'Medium', 'High', 'Extreme'])
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. ì •í™•ë„ ì•ˆì •ì„± (ë³µì¡ë„ë³„)
        for method in methods:
            if method == "OpenEMS_FDTD":
                continue  # Ground truthëŠ” ì œì™¸
                
            complexities = []
            accuracies = []
            
            for result in self.results:
                if result.method_name == method:
                    complexity = result.metadata.get('scenario_config', {}).get('complexity', 'medium')
                    complexity_level = complexity_mapping.get(complexity, 2)
                    complexities.append(complexity_level)
                    accuracies.append(result.accuracy_score)
            
            if complexities and accuracies:
                ax3.scatter(complexities, accuracies, label=method, s=100, alpha=0.7)
                
                # ì¶”ì„¸ì„  ì¶”ê°€
                if len(complexities) > 2:
                    z = np.polyfit(complexities, accuracies, 1)
                    p = np.poly1d(z)
                    x_trend = np.linspace(min(complexities), max(complexities), 100)
                    ax3.plot(x_trend, p(x_trend), "--", alpha=0.5)
        
        ax3.set_xlabel('ë¬¸ì œ ë³µì¡ë„')
        ax3.set_ylabel('ì •í™•ë„ ì ìˆ˜')
        ax3.set_title('ë¬¸ì œ í¬ê¸°ë³„ ì •í™•ë„ ì•ˆì •ì„±', fontweight='bold')
        ax3.set_xticks([1, 2, 3, 4])
        ax3.set_xticklabels(['Low', 'Medium', 'High', 'Extreme'])
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 4. íš¨ìœ¨ì„± ë³€í™”
        for method in methods:
            complexities = []
            efficiencies = []
            
            for result in self.results:
                if result.method_name == method:
                    complexity = result.metadata.get('scenario_config', {}).get('complexity', 'medium')
                    complexity_level = complexity_mapping.get(complexity, 2)
                    complexities.append(complexity_level)
                    efficiencies.append(result.efficiency_score)
            
            if complexities and efficiencies:
                ax4.scatter(complexities, efficiencies, label=method, s=100, alpha=0.7)
                
                # ì¶”ì„¸ì„  ì¶”ê°€
                if len(complexities) > 2:
                    z = np.polyfit(complexities, efficiencies, 1)
                    p = np.poly1d(z)
                    x_trend = np.linspace(min(complexities), max(complexities), 100)
                    ax4.plot(x_trend, p(x_trend), "--", alpha=0.5)
        
        ax4.set_xlabel('ë¬¸ì œ ë³µì¡ë„')
        ax4.set_ylabel('íš¨ìœ¨ì„± ì ìˆ˜')
        ax4.set_title('ë¬¸ì œ í¬ê¸°ë³„ íš¨ìœ¨ì„± ë³€í™”', fontweight='bold')
        ax4.set_xticks([1, 2, 3, 4])
        ax4.set_xticklabels(['Low', 'Medium', 'High', 'Extreme'])
        ax4.legend()
        ax4.grid(True, alpha=0.3)
        
        plt.tight_layout()
        scalability_file = self.output_dir / f"scalability_analysis_{timestamp}.png"
        plt.savefig(scalability_file, dpi=300, bbox_inches='tight')
        plt.show()
    
    def _plot_method_radar_chart(self, timestamp: str):
        """ë°©ë²•ë³„ ë ˆì´ë” ì°¨íŠ¸"""
        methods = list(set([r.method_name for r in self.results]))
        
        # í‰ê°€ ê¸°ì¤€ë“¤
        criteria = ['ì •í™•ë„', 'ì†ë„', 'ë©”ëª¨ë¦¬\níš¨ìœ¨ì„±', 'ìˆ˜ì¹˜\nì•ˆì •ì„±', 'í™•ì¥ì„±']
        
        # ê° ë°©ë²•ë³„ ì ìˆ˜ ê³„ì‚°
        method_scores = {}
        
        for method in methods:
            method_results = [r for r in self.results if r.method_name == method]
            
            if not method_results:
                continue
            
            # ì •í™•ë„ (0-1)
            accuracy = np.mean([r.accuracy_score for r in method_results])
            
            # ì†ë„ (ì—­ìˆ˜ë¥¼ ì·¨í•´ì„œ ë†’ì„ìˆ˜ë¡ ì¢‹ê²Œ)
            avg_time = np.mean([r.computation_time for r in method_results])
            speed = 1.0 / (1.0 + avg_time / 10)  # ì •ê·œí™”
            
            # ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±
            avg_memory = np.mean([r.memory_peak for r in method_results])
            memory_eff = 1.0 / (1.0 + avg_memory / 1000)  # ì •ê·œí™”
            
            # ìˆ˜ì¹˜ ì•ˆì •ì„±
            stability = np.mean([r.numerical_stability for r in method_results])
            
            # í™•ì¥ì„± (ë³µì¡ë„ ì¦ê°€ì— ë”°ë¥¸ ì„±ëŠ¥ ì €í•˜ ì •ë„)
            scalability = 0.8  # ê¸°ë³¸ê°’ (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ ê³„ì‚° í•„ìš”)
            
            method_scores[method] = [accuracy, speed, memory_eff, stability, scalability]
        
        # ë ˆì´ë” ì°¨íŠ¸ ìƒì„±
        fig, axes = plt.subplots(1, len(methods), figsize=(5*len(methods), 5), 
                                subplot_kw=dict(projection='polar'))
        
        if len(methods) == 1:
            axes = [axes]
        
        angles = np.linspace(0, 2*np.pi, len(criteria), endpoint=False).tolist()
        angles += angles[:1]  # ì›ì„ ë‹«ê¸° ìœ„í•´
        
        colors = plt.cm.Set3(np.linspace(0, 1, len(methods)))
        
        for i, (method, scores) in enumerate(method_scores.items()):
            ax = axes[i]
            
            # ì ìˆ˜ë¥¼ ì›í˜•ìœ¼ë¡œ ë§Œë“¤ê¸°
            scores_circular = scores + scores[:1]
            
            # í”Œë¡¯
            ax.plot(angles, scores_circular, 'o-', linewidth=2, color=colors[i])
            ax.fill(angles, scores_circular, alpha=0.25, color=colors[i])
            
            # ê¸°ì¤€ì„ ë“¤
            ax.set_ylim(0, 1)
            ax.set_yticks([0.2, 0.4, 0.6, 0.8, 1.0])
            ax.set_yticklabels(['0.2', '0.4', '0.6', '0.8', '1.0'])
            ax.grid(True)
            
            # ë¼ë²¨
            ax.set_xticks(angles[:-1])
            ax.set_xticklabels(criteria)
            ax.set_title(f'{method}\nì¢…í•© ì„±ëŠ¥ í”„ë¡œíŒŒì¼', size=12, fontweight='bold', pad=20)
            
            # ì ìˆ˜ í…ìŠ¤íŠ¸ ì¶”ê°€
            for angle, score, criterion in zip(angles[:-1], scores, criteria):
                ax.text(angle, score + 0.1, f'{score:.2f}', 
                       horizontalalignment='center', fontsize=10, fontweight='bold')
        
        plt.tight_layout()
        radar_file = self.output_dir / f"method_radar_chart_{timestamp}.png"
        plt.savefig(radar_file, dpi=300, bbox_inches='tight')
        plt.show()
    
    def generate_benchmark_report(self) -> str:
        """ë²¤ì¹˜ë§ˆí¬ ë³´ê³ ì„œ ìƒì„±"""
        if not self.results:
            return "ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        report = []
        report.append("=" * 80)
        report.append("ì „ìê¸° í•´ì„ ë°©ë²• ì¢…í•© ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ë³´ê³ ì„œ")
        report.append("=" * 80)
        report.append(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append(f"ì´ í…ŒìŠ¤íŠ¸ ìˆ˜: {len(self.results)}")
        
        methods = list(set([r.method_name for r in self.results]))
        scenarios = list(set([r.scenario for r in self.results]))
        
        report.append(f"í…ŒìŠ¤íŠ¸ ë°©ë²•: {', '.join(methods)}")
        report.append(f"í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤: {', '.join(scenarios)}")
        report.append("")
        
        # ë°©ë²•ë³„ ì¢…í•© ì„±ëŠ¥
        report.append("ğŸ“Š ë°©ë²•ë³„ ì¢…í•© ì„±ëŠ¥")
        report.append("-" * 50)
        
        for method in methods:
            method_results = [r for r in self.results if r.method_name == method]
            
            if method_results:
                avg_accuracy = np.mean([r.accuracy_score for r in method_results])
                avg_time = np.mean([r.computation_time for r in method_results])
                avg_memory = np.mean([r.memory_peak for r in method_results])
                avg_efficiency = np.mean([r.efficiency_score for r in method_results])
                
                report.append(f"\nğŸ”¸ {method}")
                report.append(f"   í‰ê·  ì •í™•ë„:  {avg_accuracy:.4f}")
                report.append(f"   í‰ê·  ì‹œê°„:    {avg_time:.3f}ì´ˆ")
                report.append(f"   í‰ê·  ë©”ëª¨ë¦¬:  {avg_memory:.1f}MB")
                report.append(f"   íš¨ìœ¨ì„± ì ìˆ˜:  {avg_efficiency:.4f}")
        
        # ì‹œë‚˜ë¦¬ì˜¤ë³„ ìµœì  ë°©ë²•
        report.append("\nğŸ¯ ì‹œë‚˜ë¦¬ì˜¤ë³„ ê¶Œì¥ ë°©ë²•")
        report.append("-" * 50)
        
        for scenario in scenarios:
            scenario_results = [r for r in self.results if r.scenario == scenario]
            
            if len(scenario_results) > 1:
                best_accuracy = max(scenario_results, key=lambda x: x.accuracy_score)
                best_speed = min(scenario_results, key=lambda x: x.computation_time)
                
                report.append(f"\nğŸ“‹ {scenario}:")
                report.append(f"   ì •í™•ë„ ìµœìš°ìˆ˜: {best_accuracy.method_name} ({best_accuracy.accuracy_score:.3f})")
                report.append(f"   ì†ë„ ìµœìš°ìˆ˜:   {best_speed.method_name} ({best_speed.computation_time:.3f}s)")
        
        # ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­
        report.append("\nğŸ’¡ ê²°ë¡  ë° ê¶Œì¥ì‚¬í•­")
        report.append("-" * 50)
        
        # ê°€ì¥ ê· í˜•ì¡íŒ ë°©ë²• ì°¾ê¸°
        method_balanced_scores = {}
        for method in methods:
            method_results = [r for r in self.results if r.method_name == method]
            if method_results:
                avg_accuracy = np.mean([r.accuracy_score for r in method_results])
                avg_efficiency = np.mean([r.efficiency_score for r in method_results])
                balanced_score = (avg_accuracy + avg_efficiency) / 2
                method_balanced_scores[method] = balanced_score
        
        if method_balanced_scores:
            best_balanced = max(method_balanced_scores.keys(), 
                              key=lambda x: method_balanced_scores[x])
            
            report.append(f"\nğŸ† ì¢…í•© ìµœìš°ìˆ˜ ë°©ë²•: {best_balanced}")
            report.append(f"   ê· í˜• ì ìˆ˜: {method_balanced_scores[best_balanced]:.3f}")
        
        # ì‚¬ìš© ê¶Œì¥ì‚¬í•­
        report.append("\nğŸ“‹ ì‚¬ìš© ë¶„ì•¼ë³„ ê¶Œì¥ì‚¬í•­:")
        report.append("â€¢ ì •í™•ë„ ìµœìš°ì„ : OpenEMS FDTD")
        report.append("â€¢ ì‹¤ì‹œê°„ ì˜ˆì¸¡: EM-NeRF (ì¶©ë¶„íˆ í›ˆë ¨ëœ ê²½ìš°)")
        report.append("â€¢ ê· í˜•ì¡íŒ ì„±ëŠ¥: Method of Moments (ì¤‘ê°„ ë³µì¡ë„)")
        report.append("â€¢ ë³µì¡í•œ í™˜ê²½: EM-NeRF ë˜ëŠ” FDTD")
        report.append("â€¢ ë¹ ë¥¸ í”„ë¡œí† íƒ€ì´í•‘: EM-NeRF")
        
        report_text = "\n".join(report)
        
        # íŒŒì¼ë¡œ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = self.output_dir / f"benchmark_report_{timestamp}.txt"
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report_text)
        
        logger.info(f"ë²¤ì¹˜ë§ˆí¬ ë³´ê³ ì„œ ì €ì¥: {report_file}")
        
        return report_text

# ì‚¬ìš© ì˜ˆì œ ë° ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ê³ ê¸‰ EM-NeRF ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œìŠ¤í…œ")
    print("=" * 60)
    
    # 1. ë²¤ì¹˜ë§ˆí¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    benchmark = AdvancedEMBenchmark(output_dir="em_benchmark_results")
    
    # 2. í•´ì„ê¸°ë“¤ ë“±ë¡
    fdtd_solver = OpenEMSInterface()
    benchmark.register_solver(fdtd_solver)
    
    # EM-NeRF ëª¨ë¸ ë¡œë“œ (ì‹¤ì œ ëª¨ë¸ ê²½ë¡œ ì§€ì •)
    # 1. openems_emnerf.py ì‹¤í–‰ í›„ ìƒì„±ëœ ëª¨ë¸ ì‚¬ìš©
    model_paths = [
        "best_model.pth",  # openems_emnerf.pyì—ì„œ ì €ì¥ë˜ëŠ” ê¸°ë³¸ ê²½ë¡œ
        "openems_emnerf_best.pth",  # ë‹¤ë¥¸ ê°€ëŠ¥í•œ ê²½ë¡œ
        "./models/em_nerf_trained.pth",  # ì‚¬ìš©ì ì§€ì • ê²½ë¡œ
        "./em_nerf_model.pth"  # ì¶”ê°€ ê°€ëŠ¥í•œ ê²½ë¡œ
    ]
    
    # ì¡´ì¬í•˜ëŠ” ëª¨ë¸ íŒŒì¼ ì°¾ê¸°
    model_path = None
    for path in model_paths:
        if Path(path).exists():
            model_path = path
            break
    
    if model_path:
        logger.info(f"EM-NeRF ëª¨ë¸ ë°œê²¬: {model_path}")
        emnerf_solver = EMNeRFInterface(model_path=model_path, device='auto')
        benchmark.register_solver(emnerf_solver)
    else:
        logger.warning("í•™ìŠµëœ EM-NeRF ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")
        logger.info("ëª¨ë¸ì„ ë¨¼ì € í›ˆë ¨í•˜ë ¤ë©´ 'openems_emnerf.py'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œë¼ë„ ë“±ë¡
        emnerf_solver = EMNeRFInterface(model_path=None, device='auto')
        benchmark.register_solver(emnerf_solver)
    
    mom_solver = MoMInterface()
    benchmark.register_solver(mom_solver)
    
    # 3. ì¢…í•© ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
    try:
        results = benchmark.run_comprehensive_benchmark(parallel=False)
        
        # 4. ë³´ê³ ì„œ ìƒì„±
        report = benchmark.generate_benchmark_report()
        print("\n" + report)
        
        print(f"\nğŸ‰ ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")
        print(f"ğŸ“ ê²°ê³¼ ë””ë ‰í† ë¦¬: {benchmark.output_dir}")
        print(f"ğŸ“Š ì´ {len(results)}ê°œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ")
        
    except Exception as e:
        logger.error(f"ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        raise

# ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
def load_trained_emnerf(model_path: str):
    """í›ˆë ¨ëœ EM-NeRF ëª¨ë¸ ë¡œë“œ"""
    # ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” PyTorch ëª¨ë¸ ë¡œë“œ
    logger.info(f"EM-NeRF ëª¨ë¸ ë¡œë“œ ì‹œë„: {model_path}")
    
    if not Path(model_path).exists():
        logger.warning(f"ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return None
    
    try:
        # ì‹¤ì œë¡œëŠ” torch.load(model_path) ì‚¬ìš©
        # model = torch.load(model_path, map_location='cpu')
        logger.info("EM-NeRF ëª¨ë¸ ë¡œë“œ ì„±ê³µ")
        return "dummy_model"  # ì‹¤ì œ ëª¨ë¸ ê°ì²´ ë°˜í™˜
    except Exception as e:
        logger.error(f"ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        return None

def create_custom_scenario(name: str, **kwargs) -> ScenarioConfig:
    """ì‚¬ìš©ì ì •ì˜ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±"""
    default_config = {
        'complexity': 'medium',
        'geometry_type': 'moderate',
        'frequency': 2.4e9,
        'dimensions': (1.0, 1.0, 1.0),
        'mesh_resolution': 0.01,
        'expected_advantage': 'unknown',
        'difficulty_level': 5
    }
    
    default_config.update(kwargs)
    
    return ScenarioConfig(name=name, **default_config)

class BenchmarkAnalyzer:
    """ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ë¶„ì„ ì „ìš© í´ë˜ìŠ¤"""
    
    def __init__(self, results: List[BenchmarkMetrics]):
        self.results = results
        self.methods = list(set([r.method_name for r in results]))
        self.scenarios = list(set([r.scenario for r in results]))
    
    def get_method_summary(self, method_name: str) -> Dict[str, float]:
        """íŠ¹ì • ë°©ë²•ì˜ ìš”ì•½ í†µê³„"""
        method_results = [r for r in self.results if r.method_name == method_name]
        
        if not method_results:
            return {}
        
        return {
            'count': len(method_results),
            'avg_accuracy': np.mean([r.accuracy_score for r in method_results]),
            'std_accuracy': np.std([r.accuracy_score for r in method_results]),
            'avg_time': np.mean([r.computation_time for r in method_results]),
            'std_time': np.std([r.computation_time for r in method_results]),
            'avg_memory': np.mean([r.memory_peak for r in method_results]),
            'avg_efficiency': np.mean([r.efficiency_score for r in method_results]),
            'min_time': min([r.computation_time for r in method_results]),
            'max_time': max([r.computation_time for r in method_results]),
            'min_accuracy': min([r.accuracy_score for r in method_results]),
            'max_accuracy': max([r.accuracy_score for r in method_results])
        }
    
    def compare_methods(self, method1: str, method2: str) -> Dict[str, Any]:
        """ë‘ ë°©ë²• ë¹„êµ"""
        summary1 = self.get_method_summary(method1)
        summary2 = self.get_method_summary(method2)
        
        if not summary1 or not summary2:
            return {}
        
        comparison = {
            'accuracy_difference': summary1['avg_accuracy'] - summary2['avg_accuracy'],
            'time_ratio': summary1['avg_time'] / summary2['avg_time'],
            'memory_ratio': summary1['avg_memory'] / summary2['avg_memory'],
            'efficiency_difference': summary1['avg_efficiency'] - summary2['avg_efficiency']
        }
        
        # í†µê³„ì  ìœ ì˜ì„± ê²€ì¦
        results1 = [r for r in self.results if r.method_name == method1]
        results2 = [r for r in self.results if r.method_name == method2]
        
        if len(results1) > 1 and len(results2) > 1:
            acc1 = [r.accuracy_score for r in results1]
            acc2 = [r.accuracy_score for r in results2]
            
            if len(acc1) == len(acc2):
                # Paired t-test
                stat, p_value = stats.ttest_rel(acc1, acc2)
                comparison['statistical_significance'] = p_value < 0.05
                comparison['p_value'] = p_value
            else:
                # Independent t-test
                stat, p_value = stats.ttest_ind(acc1, acc2)
                comparison['statistical_significance'] = p_value < 0.05
                comparison['p_value'] = p_value
        
        return comparison
    
    def find_optimal_method(self, criterion: str = 'balanced') -> str:
        """ìµœì  ë°©ë²• ì°¾ê¸°"""
        if criterion == 'accuracy':
            # ì •í™•ë„ ê¸°ì¤€
            method_accuracies = {}
            for method in self.methods:
                summary = self.get_method_summary(method)
                if summary:
                    method_accuracies[method] = summary['avg_accuracy']
            return max(method_accuracies.keys(), key=lambda x: method_accuracies[x])
        
        elif criterion == 'speed':
            # ì†ë„ ê¸°ì¤€
            method_times = {}
            for method in self.methods:
                summary = self.get_method_summary(method)
                if summary:
                    method_times[method] = summary['avg_time']
            return min(method_times.keys(), key=lambda x: method_times[x])
        
        elif criterion == 'balanced':
            # ê· í˜• ê¸°ì¤€ (ì •í™•ë„ + íš¨ìœ¨ì„±)
            method_scores = {}
            for method in self.methods:
                summary = self.get_method_summary(method)
                if summary:
                    balanced_score = (summary['avg_accuracy'] + summary['avg_efficiency']) / 2
                    method_scores[method] = balanced_score
            return max(method_scores.keys(), key=lambda x: method_scores[x])
        
        return self.methods[0] if self.methods else ""

class PerformanceProfiler:
    """ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.profiles = {}
    
    @contextmanager
    def profile(self, name: str):
        """í”„ë¡œíŒŒì¼ë§ ì»¨í…ìŠ¤íŠ¸"""
        start_time = time.time()
        start_memory = psutil.Process().memory_info().rss / 1024 / 1024
        
        try:
            yield
        finally:
            end_time = time.time()
            end_memory = psutil.Process().memory_info().rss / 1024 / 1024
            
            self.profiles[name] = {
                'duration': end_time - start_time,
                'memory_delta': end_memory - start_memory,
                'timestamp': datetime.now().isoformat()
            }
    
    def get_profile_summary(self) -> Dict[str, Any]:
        """í”„ë¡œíŒŒì¼ ìš”ì•½"""
        if not self.profiles:
            return {}
        
        total_time = sum([p['duration'] for p in self.profiles.values()])
        
        return {
            'total_operations': len(self.profiles),
            'total_time': total_time,
            'avg_time_per_operation': total_time / len(self.profiles),
            'operations': self.profiles
        }

# ì„¤ì • ê´€ë¦¬ í´ë˜ìŠ¤
class BenchmarkConfig:
    """ë²¤ì¹˜ë§ˆí¬ ì„¤ì • ê´€ë¦¬"""
    
    def __init__(self, config_file: Optional[str] = None):
        self.config = {
            'output_directory': 'benchmark_results',
            'parallel_execution': False,
            'max_workers': 4,
            'timeout_seconds': 300,
            'save_formats': ['json', 'csv', 'pickle'],
            'plot_formats': ['png', 'pdf'],
            'log_level': 'INFO',
            'statistical_tests': True,
            'generate_plots': True,
            'generate_report': True
        }
        
        if config_file and Path(config_file).exists():
            self.load_config(config_file)
    
    def load_config(self, config_file: str):
        """ì„¤ì • íŒŒì¼ ë¡œë“œ"""
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                user_config = json.load(f)
            self.config.update(user_config)
            logger.info(f"ì„¤ì • ë¡œë“œ ì™„ë£Œ: {config_file}")
        except Exception as e:
            logger.error(f"ì„¤ì • ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def save_config(self, config_file: str):
        """ì„¤ì • íŒŒì¼ ì €ì¥"""
        try:
            with open(config_file, 'w', encoding='utf-8') as f:
                json.dump(self.config, f, indent=2, ensure_ascii=False)
            logger.info(f"ì„¤ì • ì €ì¥ ì™„ë£Œ: {config_file}")
        except Exception as e:
            logger.error(f"ì„¤ì • ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def get(self, key: str, default=None):
        """ì„¤ì • ê°’ ê°€ì ¸ì˜¤ê¸°"""
        return self.config.get(key, default)
    
    def set(self, key: str, value):
        """ì„¤ì • ê°’ ì„¤ì •"""
        self.config[key] = value

# ì˜ˆì œ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸ë“¤
def run_quick_benchmark():
    """ë¹ ë¥¸ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
    print("âš¡ ë¹ ë¥¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
    
    benchmark = AdvancedEMBenchmark()
    
    # ê¸°ë³¸ í•´ì„ê¸°ë“¤ë§Œ ë“±ë¡
    benchmark.register_solver(OpenEMSInterface())
    benchmark.register_solver(EMNeRFInterface())
    
    # ê°„ë‹¨í•œ ì‹œë‚˜ë¦¬ì˜¤ë§Œ í…ŒìŠ¤íŠ¸
    simple_scenarios = [
        ScenarioConfig(
            name="quick_test",
            complexity="low",
            geometry_type="simple",
            frequency=2.4e9,
            dimensions=(0.3, 0.3, 0.3),
            mesh_resolution=0.05,
            difficulty_level=1
        )
    ]
    
    # ì›ë˜ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ê°„ë‹¨í•œ ê²ƒìœ¼ë¡œ ëŒ€ì²´
    benchmark.create_test_scenarios = lambda: simple_scenarios
    
    results = benchmark.run_comprehensive_benchmark(parallel=False)
    return results

def run_accuracy_focused_benchmark():
    """ì •í™•ë„ ì¤‘ì‹¬ ë²¤ì¹˜ë§ˆí¬"""
    print("ğŸ¯ ì •í™•ë„ ì¤‘ì‹¬ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰")
    
    benchmark = AdvancedEMBenchmark()
    
    # ëª¨ë“  í•´ì„ê¸° ë“±ë¡
    benchmark.register_solver(OpenEMSInterface())
    benchmark.register_solver(EMNeRFInterface())
    benchmark.register_solver(MoMInterface())
    
    # ì •í™•ë„ í…ŒìŠ¤íŠ¸ì— íŠ¹í™”ëœ ì‹œë‚˜ë¦¬ì˜¤
    accuracy_scenarios = [
        ScenarioConfig(
            name="precision_test_simple",
            complexity="low",
            geometry_type="simple",
            frequency=1e9,
            mesh_resolution=0.005,  # ê³ í•´ìƒë„
            convergence_threshold=1e-8,  # ì—„ê²©í•œ ìˆ˜ë ´ ì¡°ê±´
            difficulty_level=3
        ),
        ScenarioConfig(
            name="precision_test_complex",
            complexity="medium",
            geometry_type="moderate",
            frequency=5e9,
            mesh_resolution=0.002,
            convergence_threshold=1e-8,
            difficulty_level=6
        )
    ]
    
    benchmark.create_test_scenarios = lambda: accuracy_scenarios
    
    results = benchmark.run_comprehensive_benchmark(parallel=False)
    
    # ì •í™•ë„ ë¶„ì„
    analyzer = BenchmarkAnalyzer(results)
    
    print("\nğŸ” ì •í™•ë„ ë¶„ì„ ê²°ê³¼:")
    for method in analyzer.methods:
        if method != "OpenEMS_FDTD":  # Ground truth ì œì™¸
            summary = analyzer.get_method_summary(method)
            print(f"{method}: í‰ê·  ì •í™•ë„ {summary['avg_accuracy']:.4f} Â± {summary['std_accuracy']:.4f}")
    
    return results

def run_scalability_benchmark():
    """í™•ì¥ì„± ë²¤ì¹˜ë§ˆí¬"""
    print("ğŸ“ˆ í™•ì¥ì„± ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰")
    
    benchmark = AdvancedEMBenchmark()
    benchmark.register_solver(OpenEMSInterface())
    benchmark.register_solver(EMNeRFInterface())
    
    # í™•ì¥ì„± í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ (í¬ê¸°ë³„)
    scalability_scenarios = []
    
    sizes = [0.5, 1.0, 2.0, 4.0]  # ë‹¤ì–‘í•œ í¬ê¸°
    complexities = ['low', 'medium', 'high']
    
    for i, (size, complexity) in enumerate(zip(sizes, complexities + ['extreme'])):
        scenario = ScenarioConfig(
            name=f"scalability_test_{i+1}",
            complexity=complexity,
            geometry_type="moderate",
            frequency=2.4e9,
            dimensions=(size, size, size/2),
            mesh_resolution=0.02,
            difficulty_level=i*2 + 2
        )
        scalability_scenarios.append(scenario)
    
    benchmark.create_test_scenarios = lambda: scalability_scenarios
    
    results = benchmark.run_comprehensive_benchmark(parallel=True)
    
    # í™•ì¥ì„± ë¶„ì„
    print("\nğŸ“Š í™•ì¥ì„± ë¶„ì„:")
    for method in set([r.method_name for r in results]):
        method_results = [r for r in results if r.method_name == method]
        times = [r.computation_time for r in method_results]
        memories = [r.memory_peak for r in method_results]
        
        print(f"\n{method}:")
        print(f"  ì‹œê°„ ë²”ìœ„: {min(times):.3f} - {max(times):.3f}ì´ˆ")
        print(f"  ë©”ëª¨ë¦¬ ë²”ìœ„: {min(memories):.1f} - {max(memories):.1f}MB")
        print(f"  ì‹œê°„ ì¦ê°€ìœ¨: {max(times)/min(times):.1f}x")
    
    return results

def create_benchmark_dashboard():
    """ë²¤ì¹˜ë§ˆí¬ ëŒ€ì‹œë³´ë“œ ìƒì„±"""
    print("ğŸ“Š ë²¤ì¹˜ë§ˆí¬ ëŒ€ì‹œë³´ë“œ ìƒì„±")
    
    # ì‹¤ì œë¡œëŠ” ì›¹ ëŒ€ì‹œë³´ë“œë‚˜ GUI ìƒì„±
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ëŒ€ì‹œë³´ë“œ
    
    dashboard = """
    ================================
    EM í•´ì„ ë°©ë²• ë²¤ì¹˜ë§ˆí¬ ëŒ€ì‹œë³´ë“œ
    ================================
    
    ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ í…ŒìŠ¤íŠ¸:
    1. ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (quick)
    2. ì •í™•ë„ ì¤‘ì‹¬ í…ŒìŠ¤íŠ¸ (accuracy)  
    3. í™•ì¥ì„± í…ŒìŠ¤íŠ¸ (scalability)
    4. ì „ì²´ í…ŒìŠ¤íŠ¸ (comprehensive)
    
    ğŸ“Š ì´ì „ ê²°ê³¼ ë¶„ì„:
    - ê²°ê³¼ ë¡œë“œ ë° ë¹„êµ
    - í†µê³„ ë¶„ì„
    - ì‹œê°í™” ìƒì„±
    
    âš™ï¸ ì„¤ì •:
    - ë²¤ì¹˜ë§ˆí¬ ë§¤ê°œë³€ìˆ˜ ì¡°ì •
    - ì¶œë ¥ í˜•ì‹ ì„ íƒ
    - í•´ì„ê¸° ì„ íƒ
    """
    
    print(dashboard)
    return dashboard

# ì‚¬ìš©ì í¸ì˜ í•¨ìˆ˜ë“¤
def check_model_availability():
    """ì‚¬ìš© ê°€ëŠ¥í•œ EM-NeRF ëª¨ë¸ í™•ì¸"""
    print("ğŸ” EM-NeRF ëª¨ë¸ ìƒíƒœ í™•ì¸")
    print("=" * 50)
    
    model_paths = [
        "best_model.pth",
        "openems_emnerf_best.pth", 
        "./models/em_nerf_trained.pth",
        "./em_nerf_model.pth"
    ]
    
    found_models = []
    for path in model_paths:
        if Path(path).exists():
            size = Path(path).stat().st_size / (1024 * 1024)  # MB
            found_models.append(f"âœ… {path} ({size:.1f}MB)")
        else:
            print(f"âŒ {path} - íŒŒì¼ ì—†ìŒ")
    
    if found_models:
        print("\nì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:")
        for model in found_models:
            print(f"  {model}")
    else:
        print("\nâš ï¸  í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("ë¨¼ì € ë‹¤ìŒ ì¤‘ í•˜ë‚˜ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”:")
        print("  1. openems_emnerf.py")
        print("  2. nerf_runpod.pyì˜ run_improved_training()")
    
    print(f"\nPyTorch ì‚¬ìš© ê°€ëŠ¥: {'âœ…' if TORCH_AVAILABLE else 'âŒ'}")
    print(f"EM-NeRF ëª¨ë¸ í´ë˜ìŠ¤: {'âœ…' if EMNERF_MODEL_AVAILABLE else 'âŒ'}")
    
    return len(found_models) > 0

def train_and_benchmark():
    """í›ˆë ¨ í›„ ë°”ë¡œ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
    print("ğŸš€ EM-NeRF í›ˆë ¨ ë° ë²¤ì¹˜ë§ˆí¬ í†µí•© ì‹¤í–‰")
    print("=" * 60)
    
    # 1. ëª¨ë¸ í›ˆë ¨ (nerf_runpod.py ì‚¬ìš©)
    print("1ï¸âƒ£ EM-NeRF ëª¨ë¸ í›ˆë ¨...")
    try:
        from nerf_runpod import run_improved_training
        trainer, model = run_improved_training()
        print("âœ… ëª¨ë¸ í›ˆë ¨ ì™„ë£Œ!")
    except Exception as e:
        print(f"âŒ ëª¨ë¸ í›ˆë ¨ ì‹¤íŒ¨: {e}")
        print("nerf_runpod.pyë¥¼ ì§ì ‘ ì‹¤í–‰í•´ ì£¼ì„¸ìš”.")
        return
    
    # 2. ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
    print("\n2ï¸âƒ£ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰...")
    main()

def run_with_custom_model(model_path: str):
    """ì‚¬ìš©ì ì§€ì • ëª¨ë¸ë¡œ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
    print(f"ğŸ¯ ì‚¬ìš©ì ì§€ì • ëª¨ë¸ë¡œ ë²¤ì¹˜ë§ˆí¬: {model_path}")
    
    if not Path(model_path).exists():
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return
    
    # ë²¤ì¹˜ë§ˆí¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    benchmark = AdvancedEMBenchmark(output_dir="custom_benchmark_results")
    
    # í•´ì„ê¸°ë“¤ ë“±ë¡
    benchmark.register_solver(OpenEMSInterface())
    benchmark.register_solver(EMNeRFInterface(model_path=model_path, device='auto'))
    benchmark.register_solver(MoMInterface())
    
    # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
    try:
        results = benchmark.run_comprehensive_benchmark(parallel=False)
        report = benchmark.generate_benchmark_report()
        print("\n" + report)
        print(f"\nğŸ‰ ì‚¬ìš©ì ì§€ì • ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")
        
    except Exception as e:
        logger.error(f"ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")

# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ (ê°œì„ ëœ ë²„ì „)
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        command = sys.argv[1].lower()
        
        if command == "check":
            check_model_availability()
        elif command == "train":
            train_and_benchmark()
        elif command == "model" and len(sys.argv) > 2:
            run_with_custom_model(sys.argv[2])
        else:
            print("ì‚¬ìš©ë²•:")
            print("  python improved_openems_compare.py        # ê¸°ë³¸ ë²¤ì¹˜ë§ˆí¬")
            print("  python improved_openems_compare.py check  # ëª¨ë¸ ìƒíƒœ í™•ì¸")
            print("  python improved_openems_compare.py train  # í›ˆë ¨ í›„ ë²¤ì¹˜ë§ˆí¬")
            print("  python improved_openems_compare.py model <path>  # ì‚¬ìš©ì ëª¨ë¸")
    else:
        main()