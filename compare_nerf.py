"""
EM-NeRF vs ì „í†µì  ì „ìê¸°ì¥ ì‹œë®¬ë ˆì´ì…˜ ë°©ë²• ì„±ëŠ¥ ë¹„êµ
ì´ë¯¸ í›ˆë ¨ëœ EM-NeRF ëª¨ë¸ê³¼ ë‹¤ë¥¸ ì‹œë®¬ë ˆì´ì…˜ ë°©ì‹ë“¤ì„ ë¹„êµí•©ë‹ˆë‹¤.
"""

import torch
import torch.nn as nn
import numpy as np
import matplotlib.pyplot as plt
from scipy.interpolate import griddata, RBFInterpolator
from scipy.special import spherical_jn, spherical_yn
import time
import pandas as pd
from IPython.display import display
import seaborn as sns

# ì‹œê°í™” ì„¤ì •
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")

class TraditionalEMSimulators:
    """ì „í†µì ì¸ ì „ìê¸°ì¥ ì‹œë®¬ë ˆì´ì…˜ ë°©ë²•ë“¤"""
    
    def __init__(self, reference_data=None):
        """
        reference_data: í•™ìŠµ ë°ì´í„°ì…‹ì˜ ì¼ë¶€ë¥¼ ì°¸ì¡° ë°ì´í„°ë¡œ ì‚¬ìš©
        """
        self.reference_data = reference_data
        if reference_data:
            self.setup_interpolators()
    
    def setup_interpolators(self):
        """ë³´ê°„ê¸° ì„¤ì •"""
        # ì°¸ì¡° ë°ì´í„°ì—ì„œ ìœ„ì¹˜ì™€ í•„ë“œ ì¶”ì¶œ
        positions = self.reference_data['positions']
        e_fields = self.reference_data['e_fields']
        
        # ì„ í˜• ë³´ê°„ê¸°
        self.linear_interpolator_E = {}
        for i in range(3):
            self.linear_interpolator_E[i] = lambda p, i=i: griddata(
                positions, e_fields[:, i], p, method='linear', fill_value=0
            )
        
        # RBF ë³´ê°„ê¸° (ë” ì •í™•í•˜ì§€ë§Œ ëŠë¦¼)
        self.rbf_interpolator_E = RBFInterpolator(
            positions, e_fields, kernel='multiquadric', epsilon=2
        )
    
    def analytical_dipole(self, positions, frequency, time):
        """
        í•´ì„ì  ë‹¤ì´í´ ì•ˆí…Œë‚˜ ë°©ì‚¬ íŒ¨í„´
        ê°„ë‹¨í•œ ì „ìê¸°ì¥ ëª¨ë¸
        """
        r = np.linalg.norm(positions, axis=1, keepdims=True)
        theta = np.arccos(positions[:, 2:3] / (r + 1e-10))
        
        # íŒŒì¥ ë° íŒŒìˆ˜
        c = 3e8  # ê´‘ì†
        wavelength = c / frequency
        k = 2 * np.pi / wavelength
        
        # ì „ê¸°ì¥ (ì›ê±°ë¦¬ì¥ ê·¼ì‚¬)
        E_theta = np.sin(theta) * np.exp(-1j * k * r) / (r + 1e-10)
        E_mag = np.abs(E_theta) * 0.1  # ìŠ¤ì¼€ì¼ ì¡°ì •
        
        # 3D ë²¡í„°ë¡œ ë³€í™˜ (ê°„ë‹¨í™”)
        E_field = np.zeros((len(positions), 3))
        E_field[:, 0] = E_mag.flatten() * np.sin(theta.flatten())
        E_field[:, 1] = E_mag.flatten() * np.cos(theta.flatten())
        E_field[:, 2] = E_mag.flatten() * 0.5
        
        # ì •ê·œí™”
        E_field = np.tanh(E_field)
        
        return E_field
    
    def fdtd_approximation(self, positions, frequency, time):
        """
        FDTD (Finite-Difference Time-Domain) ê·¼ì‚¬
        ì‹¤ì œ FDTDëŠ” ë§¤ìš° ë³µì¡í•˜ë¯€ë¡œ ê°„ë‹¨í•œ ê·¼ì‚¬ ì‚¬ìš©
        """
        # ê·¸ë¦¬ë“œ ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜ì„ ì  ê¸°ë°˜ìœ¼ë¡œ ê·¼ì‚¬
        r = np.linalg.norm(positions, axis=1)
        
        # ì‹œê°„ ë„ë©”ì¸ íŒŒë™
        c = 3e8
        k = 2 * np.pi * frequency / c
        phase = k * r - 2 * np.pi * frequency * time
        
        # ì „ê¸°ì¥ ê³„ì‚°
        E_field = np.zeros((len(positions), 3))
        E_field[:, 0] = np.sin(phase) / (r + 0.1)
        E_field[:, 1] = np.cos(phase) / (r + 0.1)
        E_field[:, 2] = np.sin(2 * phase) / (r + 0.1)
        
        # ì •ê·œí™”
        E_field = np.tanh(E_field)
        
        return E_field
    
    def mom_approximation(self, positions, frequency, time):
        """
        MoM (Method of Moments) ê·¼ì‚¬
        ê²½ê³„ ìš”ì†Œë²• ê¸°ë°˜ ì‹œë®¬ë ˆì´ì…˜ì˜ ê°„ë‹¨í•œ ë²„ì „
        """
        # ëª‡ ê°œì˜ ê¸°ë³¸ í•¨ìˆ˜ë¡œ ê·¼ì‚¬
        basis_centers = np.array([
            [0, 0, 0],
            [0.5, 0, 0],
            [-0.5, 0, 0],
            [0, 0.5, 0],
            [0, -0.5, 0]
        ])
        
        E_field = np.zeros((len(positions), 3))
        
        for center in basis_centers:
            dist = np.linalg.norm(positions - center, axis=1, keepdims=True)
            weight = np.exp(-dist**2 / 0.5)
            
            # ê° ê¸°ë³¸ í•¨ìˆ˜ì˜ ê¸°ì—¬
            E_field[:, 0] += weight.flatten() * np.sin(2 * np.pi * frequency * 1e-9)
            E_field[:, 1] += weight.flatten() * np.cos(2 * np.pi * frequency * 1e-9)
            E_field[:, 2] += weight.flatten() * np.sin(4 * np.pi * frequency * 1e-9)
        
        # ì •ê·œí™”
        E_field = np.tanh(E_field / len(basis_centers))
        
        return E_field
    
    def linear_interpolation(self, positions):
        """ì„ í˜• ë³´ê°„"""
        if not hasattr(self, 'linear_interpolator_E'):
            raise ValueError("ì°¸ì¡° ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        E_field = np.zeros((len(positions), 3))
        for i in range(3):
            E_field[:, i] = self.linear_interpolator_E[i](positions)
        
        return E_field
    
    def rbf_interpolation(self, positions):
        """RBF ë³´ê°„"""
        if not hasattr(self, 'rbf_interpolator_E'):
            raise ValueError("ì°¸ì¡° ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        return self.rbf_interpolator_E(positions)

class PerformanceComparison:
    """ì„±ëŠ¥ ë¹„êµ ë° ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self, nerf_model, traditional_sims, device='cuda'):
        self.nerf_model = nerf_model.to(device)
        self.traditional_sims = traditional_sims
        self.device = device
        self.results = {}
    
    def generate_test_data(self, n_samples=1000):
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±"""
        # ê· ì¼í•˜ê²Œ ë¶„í¬ëœ í…ŒìŠ¤íŠ¸ í¬ì¸íŠ¸
        positions = torch.rand(n_samples, 3) * 2 - 1
        frequencies = torch.ones(n_samples, 1) * 0.5  # ì •ê·œí™”ëœ ì£¼íŒŒìˆ˜
        times = torch.zeros(n_samples, 1)
        dynamic_objects = torch.zeros(n_samples, 8)
        
        # Ground truth (í•©ì„± ë°ì´í„°)
        ground_truth = {
            'positions': positions.numpy(),
            'E_field': np.tanh(np.random.randn(n_samples, 3) * 0.5)
        }
        
        return {
            'positions': positions,
            'frequencies': frequencies,
            'times': times,
            'dynamic_objects': dynamic_objects,
            'ground_truth': ground_truth
        }
    
    def evaluate_method(self, method_name, method_func, test_data, use_torch=False):
        """ë‹¨ì¼ ë°©ë²• í‰ê°€"""
        print(f"\ní‰ê°€ ì¤‘: {method_name}")
        
        positions = test_data['positions']
        ground_truth = test_data['ground_truth']['E_field']
        
        # ì‹œê°„ ì¸¡ì •
        start_time = time.time()
        
        if use_torch:
            # NeRF ëª¨ë¸
            with torch.no_grad():
                predictions = method_func(
                    positions.to(self.device),
                    test_data['frequencies'].to(self.device),
                    test_data['times'].to(self.device),
                    test_data['dynamic_objects'].to(self.device)
                )
                E_pred = predictions['electric_field'].cpu().numpy()
        else:
            # ì „í†µì  ë°©ë²•
            if 'interpolation' in method_name.lower():
                E_pred = method_func(positions.numpy())
            else:
                E_pred = method_func(
                    positions.numpy(),
                    float(test_data['frequencies'][0]) * 1e10,  # ì—­ì •ê·œí™”
                    float(test_data['times'][0])
                )
        
        inference_time = time.time() - start_time
        
        # ë©”íŠ¸ë¦­ ê³„ì‚°
        mse = np.mean((E_pred - ground_truth)**2)
        mae = np.mean(np.abs(E_pred - ground_truth))
        rmse = np.sqrt(mse)
        
        # ìƒê´€ê³„ìˆ˜
        correlation = np.corrcoef(E_pred.flatten(), ground_truth.flatten())[0, 1]
        
        # ê²°ê³¼ ì €ì¥
        self.results[method_name] = {
            'MSE': mse,
            'MAE': mae,
            'RMSE': rmse,
            'Correlation': correlation,
            'Inference_Time': inference_time,
            'Time_per_Sample': inference_time / len(positions),
            'predictions': E_pred
        }
        
        print(f"  - MSE: {mse:.6f}")
        print(f"  - MAE: {mae:.6f}")
        print(f"  - Inference Time: {inference_time:.4f}s")
        print(f"  - Time per Sample: {inference_time/len(positions)*1000:.2f}ms")
    
    def run_comparison(self, n_test_samples=1000):
        """ì „ì²´ ë¹„êµ ì‹¤í–‰"""
        print("="*60)
        print("ì „ìê¸°ì¥ ì‹œë®¬ë ˆì´ì…˜ ë°©ë²• ë¹„êµ ì‹œì‘")
        print("="*60)
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        test_data = self.generate_test_data(n_test_samples)
        
        # ì°¸ì¡° ë°ì´í„° ì„¤ì • (ë³´ê°„ë²•ìš©)
        ref_data = {
            'positions': test_data['positions'].numpy()[:500],
            'e_fields': test_data['ground_truth']['E_field'][:500]
        }
        self.traditional_sims.reference_data = ref_data
        self.traditional_sims.setup_interpolators()
        
        # 1. NeRF í‰ê°€
        self.evaluate_method(
            "EM-NeRF",
            self.nerf_model,
            test_data,
            use_torch=True
        )
        
        # 2. ì „í†µì  ë°©ë²•ë“¤ í‰ê°€
        methods = {
            "Analytical Dipole": self.traditional_sims.analytical_dipole,
            "FDTD Approximation": self.traditional_sims.fdtd_approximation,
            "MoM Approximation": self.traditional_sims.mom_approximation,
            "Linear Interpolation": self.traditional_sims.linear_interpolation,
            "RBF Interpolation": self.traditional_sims.rbf_interpolation
        }
        
        for name, method in methods.items():
            try:
                self.evaluate_method(name, method, test_data)
            except Exception as e:
                print(f"  âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    def visualize_results(self):
        """ê²°ê³¼ ì‹œê°í™”"""
        # ê²°ê³¼ DataFrame ìƒì„±
        df = pd.DataFrame(self.results).T
        df = df.reset_index().rename(columns={'index': 'Method'})
        
        # 1. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¹„êµ
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        axes = axes.flatten()
        
        metrics = ['MSE', 'MAE', 'RMSE', 'Correlation', 'Inference_Time', 'Time_per_Sample']
        titles = ['Mean Squared Error', 'Mean Absolute Error', 'RMSE', 
                  'Correlation', 'Total Inference Time (s)', 'Time per Sample (s)']
        
        for i, (metric, title) in enumerate(zip(metrics, titles)):
            ax = axes[i]
            if metric in df.columns:
                df_sorted = df.sort_values(metric, ascending=(metric != 'Correlation'))
                colors = ['#2ecc71' if x == 'EM-NeRF' else '#3498db' for x in df_sorted['Method']]
                
                bars = ax.bar(range(len(df_sorted)), df_sorted[metric], color=colors)
                ax.set_xticks(range(len(df_sorted)))
                ax.set_xticklabels(df_sorted['Method'], rotation=45, ha='right')
                ax.set_title(title)
                ax.grid(True, alpha=0.3)
                
                # ê°’ í‘œì‹œ
                for bar, val in zip(bars, df_sorted[metric]):
                    height = bar.get_height()
                    ax.text(bar.get_x() + bar.get_width()/2., height,
                           f'{val:.4f}' if val < 1 else f'{val:.2f}',
                           ha='center', va='bottom', fontsize=8)
        
        plt.tight_layout()
        plt.savefig('method_comparison.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # 2. ë ˆì´ë” ì°¨íŠ¸ (ì„±ëŠ¥ í”„ë¡œíŒŒì¼)
        self.plot_radar_chart(df)
        
        # 3. ê²°ê³¼ í…Œì´ë¸”
        print("\nğŸ“Š ì„±ëŠ¥ ë¹„êµ í…Œì´ë¸”:")
        display(df.round(4))
        
        # 4. ìƒì„¸ ë¶„ì„
        self.detailed_analysis(df)
    
    def plot_radar_chart(self, df):
        """ë ˆì´ë” ì°¨íŠ¸ë¡œ ë‹¤ì°¨ì› ì„±ëŠ¥ ë¹„êµ"""
        fig = plt.figure(figsize=(10, 8))
        ax = fig.add_subplot(111, projection='polar')
        
        # ë©”íŠ¸ë¦­ ì„ íƒ (ì •ê·œí™” í•„ìš”)
        metrics = ['MSE', 'MAE', 'Inference_Time']
        
        # ì •ê·œí™” (0-1 ë²”ìœ„, ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
        normalized_data = {}
        for method in df['Method']:
            normalized_data[method] = []
            for metric in metrics:
                values = df[metric].values
                normalized_val = 1 - (df[df['Method']==method][metric].values[0] - values.min()) / (values.max() - values.min() + 1e-10)
                normalized_data[method].append(normalized_val)
        
        # ê°ë„ ì„¤ì •
        angles = np.linspace(0, 2*np.pi, len(metrics), endpoint=False).tolist()
        metrics += metrics[:1]
        angles += angles[:1]
        
        # í”Œë¡¯
        for method, values in normalized_data.items():
            values += values[:1]
            color = '#e74c3c' if method == 'EM-NeRF' else None
            ax.plot(angles, values, 'o-', linewidth=2, label=method, 
                   color=color, markersize=8)
            ax.fill(angles, values, alpha=0.15)
        
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(['MSEâ†“', 'MAEâ†“', 'Timeâ†“'])
        ax.set_ylim(0, 1)
        ax.set_title('ì„±ëŠ¥ í”„ë¡œíŒŒì¼ ë¹„êµ\n(ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ)', fontsize=14, pad=20)
        ax.legend(loc='upper right', bbox_to_anchor=(1.2, 1.1))
        ax.grid(True)
        
        plt.tight_layout()
        plt.savefig('radar_comparison.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def detailed_analysis(self, df):
        """ìƒì„¸ ë¶„ì„ ë° ì¸ì‚¬ì´íŠ¸"""
        print("\nğŸ” ìƒì„¸ ë¶„ì„:")
        print("="*60)
        
        # 1. ì •í™•ë„ ë¦¬ë”
        accuracy_leader = df.loc[df['MSE'].idxmin(), 'Method']
        print(f"âœ… ì •í™•ë„ 1ìœ„: {accuracy_leader}")
        print(f"   - MSE: {df.loc[df['MSE'].idxmin(), 'MSE']:.6f}")
        
        # 2. ì†ë„ ë¦¬ë”
        speed_leader = df.loc[df['Time_per_Sample'].idxmin(), 'Method']
        print(f"\nâš¡ ì†ë„ 1ìœ„: {speed_leader}")
        print(f"   - Time per sample: {df.loc[df['Time_per_Sample'].idxmin(), 'Time_per_Sample']*1000:.2f}ms")
        
        # 3. NeRF ë¶„ì„
        nerf_idx = df[df['Method'] == 'EM-NeRF'].index[0]
        nerf_accuracy_rank = len(df) - (df['MSE'].values <= df.loc[nerf_idx, 'MSE']).sum() + 1
        nerf_speed_rank = len(df) - (df['Time_per_Sample'].values <= df.loc[nerf_idx, 'Time_per_Sample']).sum() + 1
        
        print(f"\nğŸ§  EM-NeRF ì„±ëŠ¥:")
        print(f"   - ì •í™•ë„ ìˆœìœ„: {nerf_accuracy_rank}/{len(df)}")
        print(f"   - ì†ë„ ìˆœìœ„: {nerf_speed_rank}/{len(df)}")
        
        # 4. Trade-off ë¶„ì„
        print("\nğŸ“ˆ Trade-off ë¶„ì„:")
        for _, row in df.iterrows():
            efficiency = (1/row['MSE']) / (row['Time_per_Sample'] + 1e-10)
            print(f"   - {row['Method']}: íš¨ìœ¨ì„± ì ìˆ˜ = {efficiency:.2f}")
    
    def plot_prediction_samples(self, test_data, n_samples=5):
        """ì˜ˆì¸¡ ìƒ˜í”Œ ì‹œê°í™”"""
        fig, axes = plt.subplots(n_samples, len(self.results), figsize=(15, 3*n_samples))
        
        if n_samples == 1:
            axes = axes.reshape(1, -1)
        
        positions = test_data['positions'].numpy()
        ground_truth = test_data['ground_truth']['E_field']
        
        # ëœë¤ ìƒ˜í”Œ ì„ íƒ
        sample_indices = np.random.choice(len(positions), n_samples, replace=False)
        
        for i, idx in enumerate(sample_indices):
            for j, (method, results) in enumerate(self.results.items()):
                ax = axes[i, j]
                
                # ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ë¹„êµ
                pred = results['predictions'][idx]
                true = ground_truth[idx]
                
                x = ['Ex', 'Ey', 'Ez']
                ax.bar(np.arange(3)-0.2, true, 0.4, label='True', alpha=0.7)
                ax.bar(np.arange(3)+0.2, pred, 0.4, label='Predicted', alpha=0.7)
                
                ax.set_xticks(range(3))
                ax.set_xticklabels(x)
                ax.set_ylim(-1.5, 1.5)
                
                if i == 0:
                    ax.set_title(method)
                if j == 0:
                    ax.set_ylabel(f'Sample {idx}')
                if i == n_samples - 1 and j == len(self.results) // 2:
                    ax.legend()
                
                ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig('prediction_samples.png', dpi=300, bbox_inches='tight')
        plt.show()

# ì‹¤í–‰ ì½”ë“œ
def run_performance_comparison(trained_model):
    """í•™ìŠµëœ ëª¨ë¸ê³¼ ì „í†µì  ë°©ë²•ë“¤ì˜ ì„±ëŠ¥ ë¹„êµ ì‹¤í–‰"""
    
    # ì „í†µì  ì‹œë®¬ë ˆì´í„° ì´ˆê¸°í™”
    traditional_sims = TraditionalEMSimulators()
    
    # ë¹„êµ í´ë˜ìŠ¤ ì´ˆê¸°í™”
    comparison = PerformanceComparison(
        trained_model,
        traditional_sims,
        device='cuda' if torch.cuda.is_available() else 'cpu'
    )
    
    # ë¹„êµ ì‹¤í–‰
    comparison.run_comparison(n_test_samples=1000)
    
    # ê²°ê³¼ ì‹œê°í™”
    comparison.visualize_results()
    
    # ì˜ˆì¸¡ ìƒ˜í”Œ ì‹œê°í™”
    test_data = comparison.generate_test_data(100)
    comparison.plot_prediction_samples(test_data, n_samples=3)
    
    return comparison

# ë©”ì¸ ì‹¤í–‰ (ì£¼í”¼í„° ë…¸íŠ¸ë¶ì—ì„œ)
if __name__ == "__main__":
    print("ğŸš€ EM-NeRF ì„±ëŠ¥ ë¹„êµ ì‹œì‘...")
    print("="*60)
    
    # ì´ë¯¸ í•™ìŠµëœ ëª¨ë¸ì´ ìˆë‹¤ê³  ê°€ì • (model ë³€ìˆ˜)
    # comparison = run_performance_comparison(model)
    
    print("\nâœ… ë¹„êµ ì™„ë£Œ!")
    print("\nğŸ’¡ ì£¼ìš” ì¸ì‚¬ì´íŠ¸:")
    print("- EM-NeRFëŠ” ì—°ì†ì ì¸ í‘œí˜„ì´ ê°€ëŠ¥í•˜ë©° ì„ì˜ì˜ ìœ„ì¹˜ì—ì„œ ì¿¼ë¦¬ ê°€ëŠ¥")
    print("- ì „í†µì  ë°©ë²•ë“¤ì€ íŠ¹ì • ìƒí™©ì—ì„œ ë” ë¹ ë¥´ê±°ë‚˜ ì •í™•í•  ìˆ˜ ìˆìŒ")
    print("- ì‹¤ì œ ì‘ìš©ì—ì„œëŠ” ì •í™•ë„ì™€ ì†ë„ ê°„ì˜ trade-off ê³ ë ¤ í•„ìš”")