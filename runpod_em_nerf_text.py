#!/usr/bin/env python3
"""
RunPod GPU í…ŒìŠ¤íŠ¸ìš© ì „ìê¸°ì¥ NeRF + ë™ì‘ë¶„ì„ ì‹œìŠ¤í…œ
ì‹¤ì œ ì„±ëŠ¥ ì¸¡ì • ë° ë²¤ì¹˜ë§ˆí¬ë¥¼ ìœ„í•œ ì™„ì „í•œ êµ¬í˜„

ì‹¤í–‰ ë°©ë²•:
1. RunPod ì¸ìŠ¤í„´ìŠ¤ì— ì´ íŒŒì¼ ì—…ë¡œë“œ
2. python runpod_em_nerf_test.py
3. ê²°ê³¼ í™•ì¸

í•„ìš”í•œ GPU: RTX 4090, A100, H100 ë“± (ìµœì†Œ 12GB VRAM)
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import matplotlib.pyplot as plt
import time
import json
import os
from datetime import datetime
import psutil
import GPUtil
from typing import Dict, List, Tuple
import h5py
import cv2
from tqdm import tqdm
import logging

# GPU ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§ ì„¤ì •
torch.cuda.empty_cache()
if torch.cuda.is_available():
    print(f"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.get_device_name(0)}")
    print(f"CUDA ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SyntheticEMDataset(Dataset):
    """í•©ì„± ì „ìê¸°ì¥ ë°ì´í„°ì…‹ ìƒì„±"""
    
    def __init__(self, n_samples=50000, grid_size=64, frequency_range=(1e9, 10e9)):
        self.n_samples = n_samples
        self.grid_size = grid_size
        self.frequency_range = frequency_range
        
        logger.info(f"ë°ì´í„°ì…‹ ìƒì„± ì¤‘: {n_samples} ìƒ˜í”Œ, ê·¸ë¦¬ë“œ í¬ê¸°: {grid_size}")
        
        
        self.positions = torch.rand(n_samples, 3) * 2 - 1 
            
        self.frequencies = torch.rand(n_samples, 1) * (frequency_range[1] - frequency_range[0]) + frequency_range[0]

        self.times = torch.rand(n_samples, 1) * 1e-6  
        
        self.dynamic_objects = self.generate_dynamic_objects(n_samples)
        
        self.em_fields = self.simulate_ground_truth_fields()
        
        logger.info("ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ")
    
    def generate_dynamic_objects(self, n_samples):
        """ë™ì  ê°ì²´ ì •ë³´ ìƒì„±"""
        # [pos_x, pos_y, pos_z, vel_x, vel_y, vel_z, object_type, size]
        objects = torch.zeros(n_samples, 8)
        
        # ìœ„ì¹˜ ([-1, 1] ë²”ìœ„)
        objects[:, :3] = torch.rand(n_samples, 3) * 2 - 1
        
        # ì†ë„ ([-10, 10] m/s ë²”ìœ„)
        objects[:, 3:6] = torch.rand(n_samples, 3) * 20 - 10
        
        # ê°ì²´ íƒ€ì… (0: person, 1: car, 2: drone, 3: bird, 4: other)
        objects[:, 6] = torch.randint(0, 5, (n_samples,)).float()
        
        # í¬ê¸° (0.1 ~ 5.0 ë¯¸í„°)
        objects[:, 7] = torch.rand(n_samples) * 4.9 + 0.1
        
        return objects
    
    def simulate_ground_truth_fields(self):
        """ë¬¼ë¦¬ ê¸°ë°˜ ground truth ì „ìê¸°ì¥ ì‹œë®¬ë ˆì´ì…˜"""
        logger.info("Ground truth ì „ìê¸°ì¥ ê³„ì‚° ì¤‘...")
        
        # Maxwell ë°©ì •ì‹ ê¸°ë°˜ ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜
        n_samples = len(self.positions)
        
        # ì „ê¸°ì¥ (3ì°¨ì›)
        E_field = torch.zeros(n_samples, 3)
        
        # ìê¸°ì¥ (3ì°¨ì›)
        B_field = torch.zeros(n_samples, 3)
        
        # ì‚°ë€ ê³„ìˆ˜
        scattering = torch.zeros(n_samples, 1)
        
        # ì „íŒŒ ì§€ì—°
        delay = torch.zeros(n_samples, 1)
        
        for i in range(n_samples):
            pos = self.positions[i]
            freq = self.frequencies[i].item()
            obj = self.dynamic_objects[i]
            
            # ê±°ë¦¬ ê¸°ë°˜ ê°ì‡ 
            distance = torch.norm(pos)
            
            # ì£¼íŒŒìˆ˜ ì˜ì¡´ ì „ê¸°ì¥
            wavelength = 3e8 / freq
            k = 2 * np.pi / wavelength
            
            # ê°„ë‹¨í•œ ìŒê·¹ì ë³µì‚¬ ëª¨ë¸
            E_field[i, 0] = torch.sin(k * distance) / (distance + 0.1)
            E_field[i, 1] = torch.cos(k * distance) / (distance + 0.1)
            E_field[i, 2] = torch.sin(2 * k * distance) / (distance + 0.1)
            
            # ìê¸°ì¥ (Eì™€ ìˆ˜ì§)
            B_field[i] = torch.cross(E_field[i], torch.tensor([0., 0., 1.]))
            B_field[i] /= 3e8  # cë¡œ ë‚˜ëˆ„ì–´ ìê¸°ì¥ í¬ê¸° ì¡°ì •
            
            # ê°ì²´ì— ì˜í•œ ì‚°ë€ (í¬ê¸°ì™€ ì†ë„ì— ì˜ì¡´)
            obj_influence = torch.norm(obj[:3] - pos) 
            scattering[i] = torch.sigmoid(-obj_influence + obj[7] * 0.1)  # í¬ê¸° ì˜ì¡´
            
            # ì „íŒŒ ì§€ì—° (ê±°ë¦¬ì™€ ë§¤ì§ˆì— ì˜ì¡´)
            delay[i] = distance / 3e8 + scattering[i] * 1e-9
        
        return {
            'electric_field': E_field,
            'magnetic_field': B_field,
            'scattering_coefficient': scattering,
            'propagation_delay': delay
        }
    
    def __len__(self):
        return self.n_samples
    
    def __getitem__(self, idx):
        return {
            'position': self.positions[idx],
            'frequency': self.frequencies[idx],
            'time': self.times[idx],
            'dynamic_objects': self.dynamic_objects[idx],
            'ground_truth': {k: v[idx] for k, v in self.em_fields.items()}
        }

class OptimizedEMNeRF(nn.Module):
    """RunPod ìµœì í™”ëœ ì „ìê¸°ì¥ NeRF"""
    
    def __init__(self, hidden_dim=256, n_layers=8, use_mixed_precision=True):
        super().__init__()
        
        self.use_mixed_precision = use_mixed_precision
        
        # ìœ„ì¹˜ ì¸ì½”ë”© (íš¨ìœ¨ì ì¸ êµ¬í˜„)
        self.pos_encoding_levels = 10
        self.time_encoding_levels = 4
        
        # ì…ë ¥ ì°¨ì› ê³„ì‚°
        pos_dim = 3 + 3 * 2 * self.pos_encoding_levels  # ì›ë³¸ + sin/cos ì¸ì½”ë”©
        time_dim = 1 + 1 * 2 * self.time_encoding_levels
        freq_dim = 8  # ì£¼íŒŒìˆ˜ ì¸ì½”ë”©
        obj_dim = 8   # ë™ì  ê°ì²´
        
        input_dim = pos_dim + time_dim + freq_dim + obj_dim
        
        # íš¨ìœ¨ì ì¸ backbone ë„¤íŠ¸ì›Œí¬
        layers = []
        current_dim = input_dim
        
        for i in range(n_layers):
            # Skip connection at halfway point
            if i == n_layers // 2:
                layers.append(nn.Linear(current_dim + input_dim, hidden_dim))
            else:
                layers.append(nn.Linear(current_dim, hidden_dim))
                
            layers.append(nn.LayerNorm(hidden_dim))  # ì•ˆì •ì„±ì„ ìœ„í•œ LayerNorm
            layers.append(nn.ReLU(inplace=True))
            layers.append(nn.Dropout(0.1))  # ì˜¤ë²„í”¼íŒ… ë°©ì§€
            current_dim = hidden_dim
        
        self.backbone = nn.ModuleList(layers)
        
        # ì¶œë ¥ í—¤ë“œë“¤ (ë” íš¨ìœ¨ì ìœ¼ë¡œ)
        head_dim = hidden_dim // 2
        
        self.electric_field_head = nn.Sequential(
            nn.Linear(hidden_dim, head_dim),
            nn.ReLU(inplace=True),
            nn.Linear(head_dim, 3)
        )
        
        self.magnetic_field_head = nn.Sequential(
            nn.Linear(hidden_dim, head_dim),
            nn.ReLU(inplace=True),
            nn.Linear(head_dim, 3)
        )
        
        self.scattering_head = nn.Sequential(
            nn.Linear(hidden_dim, head_dim // 2),
            nn.ReLU(inplace=True),
            nn.Linear(head_dim // 2, 1),
            nn.Sigmoid()
        )
        
        self.delay_head = nn.Sequential(
            nn.Linear(hidden_dim, head_dim // 2),
            nn.ReLU(inplace=True),
            nn.Linear(head_dim // 2, 1)
        )
        
        # ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”
        self.apply(self._init_weights)
    
    def _init_weights(self, module):
        if isinstance(module, nn.Linear):
            torch.nn.init.kaiming_normal_(module.weight, nonlinearity='relu')
            if module.bias is not None:
                torch.nn.init.zeros_(module.bias)
    
    def positional_encoding(self, x, levels):
        """íš¨ìœ¨ì ì¸ ìœ„ì¹˜ ì¸ì½”ë”©"""
        encoded = [x]
        for level in range(levels):
            for fn in [torch.sin, torch.cos]:
                encoded.append(fn(2**level * np.pi * x))
        return torch.cat(encoded, dim=-1)
    
    def frequency_encoding(self, freq):
        """ì£¼íŒŒìˆ˜ ì¸ì½”ë”©"""
        # ë¡œê·¸ ìŠ¤ì¼€ì¼ë¡œ ì •ê·œí™”
        log_freq = torch.log10(torch.clamp(freq, min=1e6, max=1e12))
        normalized = (log_freq - 6) / 6  # [1MHz, 1THz] -> [-1, 1]
        
        # ìœ„ì¹˜ ì¸ì½”ë”© ìŠ¤íƒ€ì¼
        encoded = [normalized]
        for i in range(3):
            encoded.append(torch.sin(2**i * np.pi * normalized))
            encoded.append(torch.cos(2**i * np.pi * normalized))
        
        return torch.cat(encoded, dim=-1)
    
    def forward(self, positions, frequencies, times, dynamic_objects):
        batch_size = positions.shape[0]
        
        # ì¸ì½”ë”©
        pos_encoded = self.positional_encoding(positions, self.pos_encoding_levels)
        time_encoded = self.positional_encoding(times, self.time_encoding_levels)
        freq_encoded = self.frequency_encoding(frequencies)
        
        # ë™ì  ê°ì²´ ì •ê·œí™”
        obj_normalized = torch.tanh(dynamic_objects)
        
        # íŠ¹ì§• ê²°í•©
        features = torch.cat([pos_encoded, time_encoded, freq_encoded, obj_normalized], dim=1)
        
        # Backbone í†µê³¼ (skip connection í¬í•¨)
        skip_input = features
        x = features
        
        for i, layer in enumerate(self.backbone):
            if isinstance(layer, nn.Linear) and layer.in_features == x.shape[1] + skip_input.shape[1]:
                # Skip connection
                x = torch.cat([x, skip_input], dim=1)
            x = layer(x)
        
        # ì¶œë ¥ ê³„ì‚°
        E_field = self.electric_field_head(x)
        B_field = self.magnetic_field_head(x)
        scattering = self.scattering_head(x)
        delay = self.delay_head(x)
        
        return {
            'electric_field': E_field,
            'magnetic_field': B_field,
            'scattering_coefficient': scattering,
            'propagation_delay': delay
        }

class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.metrics = {
            'gpu_memory': [],
            'gpu_utilization': [],
            'training_loss': [],
            'inference_time': [],
            'throughput': [],
            'cpu_usage': [],
            'system_memory': []
        }
        
    def update(self, **kwargs):
        # GPU ì •ë³´ ìˆ˜ì§‘
        if torch.cuda.is_available():
            gpu = GPUtil.getGPUs()[0]
            self.metrics['gpu_memory'].append(gpu.memoryUsed / gpu.memoryTotal * 100)
            self.metrics['gpu_utilization'].append(gpu.load * 100)
        
        # CPU ë° ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬
        self.metrics['cpu_usage'].append(psutil.cpu_percent())
        self.metrics['system_memory'].append(psutil.virtual_memory().percent)
        
        # ì¶”ê°€ ë©”íŠ¸ë¦­
        for key, value in kwargs.items():
            if key in self.metrics:
                self.metrics[key].append(value)
    
    def get_summary(self):
        summary = {}
        for key, values in self.metrics.items():
            if values:
                summary[key] = {
                    'mean': np.mean(values),
                    'max': np.max(values),
                    'min': np.min(values),
                    'std': np.std(values)
                }
        return summary
    
    def save_report(self, filepath):
        report = {
            'timestamp': datetime.now().isoformat(),
            'system_info': {
                'gpu_name': torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'CPU',
                'gpu_memory_total': torch.cuda.get_device_properties(0).total_memory / 1e9 if torch.cuda.is_available() else 0,
                'cpu_count': os.cpu_count(),
                'system_memory': psutil.virtual_memory().total / 1e9
            },
            'metrics': self.get_summary(),
            'raw_data': self.metrics
        }
        
        with open(filepath, 'w') as f:
            json.dump(report, f, indent=2, default=str)
        
        logger.info(f"ì„±ëŠ¥ ë¦¬í¬íŠ¸ ì €ì¥ë¨: {filepath}")

class EMNeRFTrainer:
    """ìµœì í™”ëœ NeRF íŠ¸ë ˆì´ë„ˆ"""
    
    def __init__(self, model, device='cuda', use_mixed_precision=True):
        self.model = model.to(device)
        self.device = device
        self.use_mixed_precision = use_mixed_precision
        
        # ì˜µí‹°ë§ˆì´ì € (AdamW ì‚¬ìš©)
        self.optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-5)
        
        # ìŠ¤ì¼€ì¤„ëŸ¬
        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=1000)
        
        # Mixed precision scaler
        self.scaler = torch.cuda.amp.GradScaler() if use_mixed_precision else None
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°
        self.monitor = PerformanceMonitor()
    
    def physics_loss(self, predictions, targets):
        """ë¬¼ë¦¬ ê¸°ë°˜ ì†ì‹¤ í•¨ìˆ˜"""
        mse_loss = nn.MSELoss()
        
        # ê¸°ë³¸ MSE ì†ì‹¤
        e_loss = mse_loss(predictions['electric_field'], targets['electric_field'])
        b_loss = mse_loss(predictions['magnetic_field'], targets['magnetic_field'])
        s_loss = mse_loss(predictions['scattering_coefficient'], targets['scattering_coefficient'])
        d_loss = mse_loss(predictions['propagation_delay'], targets['propagation_delay'])
        
        # ë¬¼ë¦¬ ë²•ì¹™ ì œì•½ (ê°„ë‹¨í•œ ë²„ì „)
        # |E| ì™€ |B| ì˜ ê´€ê³„: |B| â‰ˆ |E|/c
        E_magnitude = torch.norm(predictions['electric_field'], dim=1)
        B_magnitude = torch.norm(predictions['magnetic_field'], dim=1)
        c = 3e8
        physics_constraint = mse_loss(B_magnitude * c, E_magnitude)
        
        total_loss = e_loss + b_loss + s_loss + d_loss + 0.1 * physics_constraint
        
        return {
            'total': total_loss,
            'electric': e_loss,
            'magnetic': b_loss,
            'scattering': s_loss,
            'delay': d_loss,
            'physics': physics_constraint
        }
    
    def train_epoch(self, dataloader):
        self.model.train()
        epoch_losses = []
        
        for batch_idx, batch in enumerate(tqdm(dataloader, desc="Training")):
            # ë°ì´í„° GPUë¡œ ì´ë™
            positions = batch['position'].to(self.device)
            frequencies = batch['frequency'].to(self.device)
            times = batch['time'].to(self.device)
            dynamic_objects = batch['dynamic_objects'].to(self.device)
            
            targets = {k: v.to(self.device) for k, v in batch['ground_truth'].items()}
            
            self.optimizer.zero_grad()
            
            # Forward pass with mixed precision
            if self.use_mixed_precision:
                with torch.cuda.amp.autocast():
                    predictions = self.model(positions, frequencies, times, dynamic_objects)
                    losses = self.physics_loss(predictions, targets)
                    total_loss = losses['total']
                
                # Backward pass
                self.scaler.scale(total_loss).backward()
                self.scaler.step(self.optimizer)
                self.scaler.update()
            else:
                predictions = self.model(positions, frequencies, times, dynamic_objects)
                losses = self.physics_loss(predictions, targets)
                total_loss = losses['total']
                
                total_loss.backward()
                self.optimizer.step()
            
            epoch_losses.append(total_loss.item())
            
            # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
            if batch_idx % 10 == 0:
                self.monitor.update(training_loss=total_loss.item())
        
        self.scheduler.step()
        return np.mean(epoch_losses)
    
    def benchmark_inference(self, test_dataloader, n_iterations=100):
        """ì¶”ë¡  ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
        self.model.eval()
        inference_times = []
        
        logger.info(f"ì¶”ë¡  ë²¤ì¹˜ë§ˆí¬ ì‹œì‘ ({n_iterations} ë°˜ë³µ)")
        
        with torch.no_grad():
            for i, batch in enumerate(test_dataloader):
                if i >= n_iterations:
                    break
                
                # ë°ì´í„° ì¤€ë¹„
                positions = batch['position'].to(self.device)
                frequencies = batch['frequency'].to(self.device)
                times = batch['time'].to(self.device)
                dynamic_objects = batch['dynamic_objects'].to(self.device)
                
                # ì¶”ë¡  ì‹œê°„ ì¸¡ì •
                torch.cuda.synchronize()
                start_time = time.time()
                
                if self.use_mixed_precision:
                    with torch.cuda.amp.autocast():
                        predictions = self.model(positions, frequencies, times, dynamic_objects)
                else:
                    predictions = self.model(positions, frequencies, times, dynamic_objects)
                
                torch.cuda.synchronize()
                end_time = time.time()
                
                inference_time = end_time - start_time
                inference_times.append(inference_time)
                
                # ì²˜ë¦¬ëŸ‰ ê³„ì‚° (samples per second)
                throughput = len(positions) / inference_time
                self.monitor.update(inference_time=inference_time, throughput=throughput)
        
        return {
            'mean_inference_time': np.mean(inference_times),
            'std_inference_time': np.std(inference_times),
            'max_inference_time': np.max(inference_times),
            'min_inference_time': np.min(inference_times),
            'mean_throughput': np.mean([len(batch['position']) / t for t in inference_times])
        }

def run_full_benchmark():
    """ì „ì²´ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
    logger.info("=== RunPod ì „ìê¸°ì¥ NeRF ë²¤ì¹˜ë§ˆí¬ ì‹œì‘ ===")
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    logger.info(f"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    
    # ë°ì´í„°ì…‹ ìƒì„±
    logger.info("ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
    train_dataset = SyntheticEMDataset(n_samples=10000, grid_size=64)
    test_dataset = SyntheticEMDataset(n_samples=2000, grid_size=64)
    
    # ë°ì´í„°ë¡œë”
    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)
    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)
    
    # ëª¨ë¸ ìƒì„±
    logger.info("ëª¨ë¸ ì´ˆê¸°í™” ì¤‘...")
    model = OptimizedEMNeRF(hidden_dim=256, n_layers=8, use_mixed_precision=True)
    
    # íŠ¸ë ˆì´ë„ˆ ìƒì„±
    trainer = EMNeRFTrainer(model, device=device, use_mixed_precision=True)
    
    # í›ˆë ¨ ì‹¤í–‰
    logger.info("í›ˆë ¨ ì‹œì‘...")
    n_epochs = 50
    
    for epoch in range(n_epochs):
        start_time = time.time()
        epoch_loss = trainer.train_epoch(train_loader)
        epoch_time = time.time() - start_time
        
        if epoch % 10 == 0:
            logger.info(f"Epoch {epoch}/{n_epochs}, Loss: {epoch_loss:.6f}, Time: {epoch_time:.2f}s")
    
    # ì¶”ë¡  ë²¤ì¹˜ë§ˆí¬
    logger.info("ì¶”ë¡  ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘...")
    inference_results = trainer.benchmark_inference(test_loader, n_iterations=50)
    
    # ê²°ê³¼ ì¶œë ¥
    logger.info("\n=== ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ===")
    logger.info(f"í‰ê·  ì¶”ë¡  ì‹œê°„: {inference_results['mean_inference_time']:.4f}s")
    logger.info(f"í‰ê·  ì²˜ë¦¬ëŸ‰: {inference_results['mean_throughput']:.1f} samples/sec")
    
    # ì„±ëŠ¥ ë¦¬í¬íŠ¸ ì €ì¥
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    report_path = f"em_nerf_benchmark_{timestamp}.json"
    trainer.monitor.save_report(report_path)
    
    # ëª¨ë¸ ì €ì¥
    model_path = f"em_nerf_model_{timestamp}.pth"
    torch.save({
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': trainer.optimizer.state_dict(),
        'benchmark_results': inference_results,
        'model_config': {
            'hidden_dim': 256,
            'n_layers': 8,
            'use_mixed_precision': True
        }
    }, model_path)
    
    logger.info(f"ëª¨ë¸ ì €ì¥ë¨: {model_path}")
    
    return {
        'model_path': model_path,
        'report_path': report_path,
        'benchmark_results': inference_results,
        'performance_summary': trainer.monitor.get_summary()
    }

def visualize_results(model_path, save_plots=True):
    """ê²°ê³¼ ì‹œê°í™”"""
    logger.info("ê²°ê³¼ ì‹œê°í™” ìƒì„± ì¤‘...")
    
    # ëª¨ë¸ ë¡œë“œ
    checkpoint = torch.load(model_path)
    model = OptimizedEMNeRF()
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model.to(device)
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
    n_points = 1000
    positions = torch.rand(n_points, 3) * 2 - 1
    frequencies = torch.full((n_points, 1), 2.4e9)  # 2.4GHz
    times = torch.zeros(n_points, 1)
    dynamic_objects = torch.zeros(n_points, 8)
    
    # GPUë¡œ ì´ë™
    positions = positions.to(device)
    frequencies = frequencies.to(device)
    times = times.to(device)
    dynamic_objects = dynamic_objects.to(device)
    
    # ì˜ˆì¸¡
    with torch.no_grad():
        predictions = model(positions, frequencies, times, dynamic_objects)
    
    # CPUë¡œ ì´ë™
    for key in predictions:
        predictions[key] = predictions[key].cpu().numpy()
    positions = positions.cpu().numpy()
    
    # í”Œë¡¯ ìƒì„±
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # ì „ê¸°ì¥ í¬ê¸°
    E_magnitude = np.linalg.norm(predictions['electric_field'], axis=1)
    scatter1 = axes[0, 0].scatter(positions[:, 0], positions[:, 1], c=E_magnitude, cmap='viridis')
    axes[0, 0].set_title('Electric Field Magnitude')
    axes[0, 0].set_xlabel('X Position')
    axes[0, 0].set_ylabel('Y Position')
    plt.colorbar(scatter1, ax=axes[0, 0])
    
    # ìê¸°ì¥ í¬ê¸°
    B_magnitude = np.linalg.norm(predictions['magnetic_field'], axis=1)
    scatter2 = axes[0, 1].scatter(positions[:, 0], positions[:, 1], c=B_magnitude, cmap='plasma')
    axes[0, 1].set_title('Magnetic Field Magnitude')
    axes[0, 1].set_xlabel('X Position')
    axes[0, 1].set_ylabel('Y Position')
    plt.colorbar(scatter2, ax=axes[0, 1])
    
    # ì‚°ë€ ê³„ìˆ˜
    scattering = predictions['scattering_coefficient'].flatten()
    scatter3 = axes[1, 0].scatter(positions[:, 0], positions[:, 1], c=scattering, cmap='coolwarm')
    axes[1, 0].set_title('Scattering Coefficient')
    axes[1, 0].set_xlabel('X Position')
    axes[1, 0].set_ylabel('Y Position')
    plt.colorbar(scatter3, ax=axes[1, 0])
    
    # ì „íŒŒ ì§€ì—°
    delay = predictions['propagation_delay'].flatten() * 1e9  # nanoseconds
    scatter4 = axes[1, 1].scatter(positions[:, 0], positions[:, 1], c=delay, cmap='inferno')
    axes[1, 1].set_title('Propagation Delay (ns)')
    axes[1, 1].set_xlabel('X Position')
    axes[1, 1].set_ylabel('Y Position')
    plt.colorbar(scatter4, ax=axes[1, 1])
    
    plt.tight_layout()
    
    if save_plots:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        plot_path = f"em_field_visualization_{timestamp}.png"
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        logger.info(f"ì‹œê°í™” ì €ì¥ë¨: {plot_path}")
        return plot_path
    else:
        plt.show()
        return None

if __name__ == "__main__":
    try:
        # ì „ì²´ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
        results = run_full_benchmark()
        
        # ê²°ê³¼ ì‹œê°í™”
        plot_path = visualize_results(results['model_path'])
        
        print("\n" + "="*50)
        print("ğŸ¯ RunPod ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")
        print("="*50)
        print(f"ğŸ“Š ì„±ëŠ¥ ë¦¬í¬íŠ¸: {results['report_path']}")
        print(f"ğŸ¤– ëª¨ë¸ íŒŒì¼: {results['model_path']}")
        print(f"ğŸ“ˆ ì‹œê°í™”: {plot_path}")
        print("\nì£¼ìš” ì„±ëŠ¥ ì§€í‘œ:")
        benchmark = results['benchmark_results']
        print(f"  â€¢ í‰ê·  ì¶”ë¡  ì‹œê°„: {benchmark['mean_inference_time']:.4f}ì´ˆ")
        print(f"  â€¢ ì²˜ë¦¬ëŸ‰: {benchmark['mean_throughput']:.1f} samples/sec")
        print(f"  â€¢ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ : {results['performance_summary'].get('gpu_memory', {}).get('mean', 0):.1f}%")
        
        # ì‹¤ì œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ê°€ì´ë“œ ì¶œë ¥
        print("\n" + "="*50)
        print("ğŸ“ ì‹¤ì œ ë°ì´í„°ì…‹ ì‚¬ìš© ê°€ì´ë“œ")
        print("="*50)
        print("1. ê³µê°œ RF ë°ì´í„°ì…‹:")
        print("   â€¢ NIST RF ì „íŒŒ ì¸¡ì • ë°ì´í„°: https://its.ntia.gov/")
        print("   â€¢ DeepSig RadioML ë°ì´í„°ì…‹: https://www.deepsig.ai/datasets/")
        print("   â€¢ Kaggle RF Signal ë°ì´í„°: https://www.kaggle.com/datasets/suraj520/rf-signal-data")
        print("\n2. ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°:")
        print("   â€¢ MATLAB RF Propagation íˆ´ë°•ìŠ¤ ì¶œë ¥")
        print("   â€¢ CST Studio Suite ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼")
        print("   â€¢ FEKO ì „ìê¸°ì¥ ì‹œë®¬ë ˆì´ì…˜")
        
    except Exception as e:
        logger.error(f"ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

# ì¶”ê°€ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤

def download_real_datasets():
    """ì‹¤ì œ ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ë° ì „ì²˜ë¦¬ í•¨ìˆ˜"""
    import urllib.request
    import zipfile
    
    logger.info("ì‹¤ì œ RF ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ ì¤‘...")
    
    datasets = {
        'deepsig_radioml': {
            'url': 'https://www.deepsig.ai/datasets/2016.10a.tar.bz2',
            'description': 'RadioML 2016.10a - ë³€ì¡° ì¸ì‹ìš© RF ì‹ í˜¸ ë°ì´í„°'
        },
        'nist_rf_data': {
            'url': 'https://its.ntia.gov/public-data/spectrum-measurements/',
            'description': 'NIST RF ì „íŒŒ ì¸¡ì • ë°ì´í„° (ë©”íƒ€ë°ì´í„°ë§Œ)'
        }
    }
    
    # ì‹¤ì œ ë‹¤ìš´ë¡œë“œëŠ” ìš©ëŸ‰ ë¬¸ì œë¡œ ì£¼ì„ ì²˜ë¦¬
    # ì‚¬ìš©ìê°€ í•„ìš”ì— ë”°ë¼ í™œì„±í™”
    """
    for name, info in datasets.items():
        try:
            print(f"ë‹¤ìš´ë¡œë“œ ì¤‘: {name}")
            print(f"ì„¤ëª…: {info['description']}")
            print(f"URL: {info['url']}")
            # urllib.request.urlretrieve(info['url'], f"{name}.tar.bz2")
            print("ìˆ˜ë™ ë‹¤ìš´ë¡œë“œ í•„ìš” (ìš©ëŸ‰ ì œí•œ)")
        except Exception as e:
            print(f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ {name}: {e}")
    """
    
    return datasets

def create_runpod_setup_script():
    """RunPod ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„±"""
    setup_script = """#!/bin/bash
# RunPod GPU ì¸ìŠ¤í„´ìŠ¤ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸

echo "RunPod ì „ìê¸°ì¥ NeRF í™˜ê²½ ì„¤ì • ì‹œì‘..."

# í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install matplotlib numpy tqdm h5py opencv-python psutil gputil
pip install scipy scikit-learn pandas seaborn

# ë©”ëª¨ë¦¬ ìµœì í™” ì„¤ì •
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128

# ì‘ì—… ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p /workspace/em_nerf_test
cd /workspace/em_nerf_test

# ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬
chmod +x runpod_em_nerf_test.py

echo "ì„¤ì • ì™„ë£Œ! ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ë²¤ì¹˜ë§ˆí¬ë¥¼ ì‹œì‘í•˜ì„¸ìš”:"
echo "python runpod_em_nerf_test.py"
"""
    
    with open("setup_runpod.sh", "w") as f:
        f.write(setup_script)
    
    logger.info("RunPod ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ìƒì„±ë¨: setup_runpod.sh")

def memory_profiler():
    """GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í”„ë¡œíŒŒì¼ë§"""
    if not torch.cuda.is_available():
        print("CUDA ì‚¬ìš© ë¶ˆê°€ëŠ¥")
        return
    
    print("\n=== GPU ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§ ===")
    
    # ë‹¤ì–‘í•œ ë°°ì¹˜ í¬ê¸°ì—ì„œ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í…ŒìŠ¤íŠ¸
    model = OptimizedEMNeRF(hidden_dim=256, n_layers=8).cuda()
    batch_sizes = [1, 4, 8, 16, 32, 64, 128, 256]
    
    results = []
    
    for batch_size in batch_sizes:
        try:
            torch.cuda.empty_cache()
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
            positions = torch.rand(batch_size, 3).cuda()
            frequencies = torch.rand(batch_size, 1).cuda() * 1e9 + 1e9
            times = torch.rand(batch_size, 1).cuda() * 1e-6
            dynamic_objects = torch.rand(batch_size, 8).cuda()
            
            # ë©”ëª¨ë¦¬ ì¸¡ì •
            torch.cuda.synchronize()
            memory_before = torch.cuda.memory_allocated() / 1e6  # MB
            
            with torch.no_grad():
                output = model(positions, frequencies, times, dynamic_objects)
            
            torch.cuda.synchronize()
            memory_after = torch.cuda.memory_allocated() / 1e6  # MB
            
            memory_used = memory_after - memory_before
            
            results.append({
                'batch_size': batch_size,
                'memory_used_mb': memory_used,
                'memory_per_sample': memory_used / batch_size if batch_size > 0 else 0
            })
            
            print(f"ë°°ì¹˜ í¬ê¸° {batch_size:3d}: {memory_used:6.1f} MB ({memory_used/batch_size:.2f} MB/sample)")
            
        except RuntimeError as e:
            if "out of memory" in str(e):
                print(f"ë°°ì¹˜ í¬ê¸° {batch_size}: GPU ë©”ëª¨ë¦¬ ë¶€ì¡±")
                break
            else:
                raise e
    
    return results

def create_data_conversion_utils():
    """ì‹¤ì œ ë°ì´í„°ì…‹ ë³€í™˜ ìœ í‹¸ë¦¬í‹°"""
    
    def convert_matlab_to_pytorch(mat_file_path):
        """MATLAB .mat íŒŒì¼ì„ PyTorch í…ì„œë¡œ ë³€í™˜"""
        try:
            import scipy.io
            
            mat_data = scipy.io.loadmat(mat_file_path)
            
            # ì¼ë°˜ì ì¸ RF ë°ì´í„° êµ¬ì¡° ê°€ì •
            if 'signal_data' in mat_data:
                signals = torch.tensor(mat_data['signal_data'], dtype=torch.float32)
            
            if 'coordinates' in mat_data:
                coordinates = torch.tensor(mat_data['coordinates'], dtype=torch.float32)
            
            if 'frequencies' in mat_data:
                frequencies = torch.tensor(mat_data['frequencies'], dtype=torch.float32)
            
            return {
                'signals': signals,
                'coordinates': coordinates,
                'frequencies': frequencies
            }
            
        except ImportError:
            print("scipy ì„¤ì¹˜ í•„ìš”: pip install scipy")
            return None
        except Exception as e:
            print(f"MATLAB íŒŒì¼ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None
    
    def convert_cst_to_pytorch(cst_export_path):
        """CST Studio Suite ë‚´ë³´ë‚´ê¸° íŒŒì¼ì„ PyTorch í˜•íƒœë¡œ ë³€í™˜"""
        # CSTëŠ” ë³´í†µ ASCII í˜•íƒœë¡œ ë°ì´í„°ë¥¼ ë‚´ë³´ëƒ„
        try:
            import pandas as pd
            
            # CSV í˜•íƒœë¡œ ë‚´ë³´ë‚¸ ê²½ìš°
            if cst_export_path.endswith('.csv'):
                df = pd.read_csv(cst_export_path)
                
                # ì¼ë°˜ì ì¸ ì»¬ëŸ¼ëª…ë“¤
                position_cols = ['X', 'Y', 'Z']
                field_cols = ['Ex', 'Ey', 'Ez', 'Bx', 'By', 'Bz']
                
                positions = torch.tensor(df[position_cols].values, dtype=torch.float32)
                
                # ì „ê¸°ì¥
                if all(col in df.columns for col in ['Ex', 'Ey', 'Ez']):
                    e_field = torch.tensor(df[['Ex', 'Ey', 'Ez']].values, dtype=torch.float32)
                else:
                    e_field = None
                
                # ìê¸°ì¥
                if all(col in df.columns for col in ['Bx', 'By', 'Bz']):
                    b_field = torch.tensor(df[['Bx', 'By', 'Bz']].values, dtype=torch.float32)
                else:
                    b_field = None
                
                return {
                    'positions': positions,
                    'electric_field': e_field,
                    'magnetic_field': b_field
                }
            
        except Exception as e:
            print(f"CST íŒŒì¼ ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None
    
    return convert_matlab_to_pytorch, convert_cst_to_pytorch

# ì„±ëŠ¥ ë¹„êµë¥¼ ìœ„í•œ ê¸°ì¤€ ëª¨ë¸ë“¤
class BaselineModels:
    """ë¹„êµë¥¼ ìœ„í•œ ê¸°ì¤€ ëª¨ë¸ë“¤"""
    
    @staticmethod
    def simple_mlp():
        """ê°„ë‹¨í•œ MLP ê¸°ì¤€ ëª¨ë¸"""
        return nn.Sequential(
            nn.Linear(3 + 1 + 1 + 8, 128),  # pos + freq + time + obj
            nn.ReLU(),
            nn.Linear(128, 128),
            nn.ReLU(),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Linear(64, 7)  # E(3) + B(3) + scattering(1)
        )
    
    @staticmethod
    def physics_informed_mlp():
        """ë¬¼ë¦¬ ë²•ì¹™ì´ ì¶”ê°€ëœ MLP"""
        class PhysicsMLPModel(nn.Module):
            def __init__(self):
                super().__init__()
                self.mlp = nn.Sequential(
                    nn.Linear(13, 256),
                    nn.ReLU(),
                    nn.Linear(256, 256),
                    nn.ReLU(),
                    nn.Linear(256, 128),
                    nn.ReLU(),
                    nn.Linear(128, 7)
                )
            
            def forward(self, positions, frequencies, times, dynamic_objects):
                x = torch.cat([positions, frequencies, times, dynamic_objects], dim=1)
                output = self.mlp(x)
                
                return {
                    'electric_field': output[:, :3],
                    'magnetic_field': output[:, 3:6],
                    'scattering_coefficient': torch.sigmoid(output[:, 6:7]),
                    'propagation_delay': torch.abs(output[:, 6:7]) * 1e-9
                }
        
        return PhysicsMLPModel()

def run_comparative_benchmark():
    """ë‹¤ì–‘í•œ ëª¨ë¸ë“¤ì˜ ì„±ëŠ¥ ë¹„êµ"""
    logger.info("=== ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ë²¤ì¹˜ë§ˆí¬ ===")
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°
    test_dataset = SyntheticEMDataset(n_samples=1000)
    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)
    
    models = {
        'EM-NeRF (Ours)': OptimizedEMNeRF(hidden_dim=256, n_layers=8),
        'Simple MLP': BaselineModels.simple_mlp(),
        'Physics MLP': BaselineModels.physics_informed_mlp()
    }
    
    results = {}
    
    for name, model in models.items():
        logger.info(f"ë²¤ì¹˜ë§ˆí‚¹: {name}")
        
        model = model.to(device)
        
        # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
        n_params = sum(p.numel() for p in model.parameters())
        
        # ì¶”ë¡  ì‹œê°„ ì¸¡ì •
        inference_times = []
        
        model.eval()
        with torch.no_grad():
            for batch in test_loader:
                positions = batch['position'].to(device)
                frequencies = batch['frequency'].to(device)
                times = batch['time'].to(device)
                dynamic_objects = batch['dynamic_objects'].to(device)
                
                torch.cuda.synchronize()
                start_time = time.time()
                
                if isinstance(model, nn.Sequential):
                    # Simple MLP ì¼€ì´ìŠ¤
                    x = torch.cat([positions, frequencies, times, dynamic_objects], dim=1)
                    _ = model(x)
                else:
                    _ = model(positions, frequencies, times, dynamic_objects)
                
                torch.cuda.synchronize()
                end_time = time.time()
                
                inference_times.append(end_time - start_time)
        
        results[name] = {
            'parameters': n_params,
            'mean_inference_time': np.mean(inference_times),
            'throughput': 32 / np.mean(inference_times)  # samples/sec
        }
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "="*60)
    print("ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ê²°ê³¼")
    print("="*60)
    print(f"{'ëª¨ë¸ëª…':<20} {'íŒŒë¼ë¯¸í„°':<15} {'ì¶”ë¡ ì‹œê°„(s)':<15} {'ì²˜ë¦¬ëŸ‰(sps)':<15}")
    print("-"*60)
    
    for name, metrics in results.items():
        print(f"{name:<20} {metrics['parameters']:<15,} {metrics['mean_inference_time']:<15.4f} {metrics['throughput']:<15.1f}")
    
    return results

# RunPod ì‹¤í–‰ ê°€ì´ë“œ ì¶œë ¥
def print_runpod_guide():
    """RunPod ì‚¬ìš© ê°€ì´ë“œ ì¶œë ¥"""
    
    guide = """
ğŸš€ RunPod GPU ì¸ìŠ¤í„´ìŠ¤ ì‹¤í–‰ ê°€ì´ë“œ
================================

1. RunPod ê³„ì • ìƒì„± ë° GPU ì¸ìŠ¤í„´ìŠ¤ ì‹œì‘
   - https://runpod.io ì ‘ì†
   - RTX 4090, A100, H100 ë“± ì„ íƒ (ê¶Œì¥: 12GB+ VRAM)
   - PyTorch 2.0+ í…œí”Œë¦¿ ì„ íƒ

2. íŒŒì¼ ì—…ë¡œë“œ
   - ì´ Python íŒŒì¼ì„ /workspace/ ë””ë ‰í† ë¦¬ì— ì—…ë¡œë“œ
   - setup_runpod.sh ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ìœ¼ë¡œ í™˜ê²½ ì„¤ì •

3. ì‹¤í–‰ ëª…ë ¹ì–´
   ```bash
   cd /workspace
   chmod +x setup_runpod.sh
   ./setup_runpod.sh
   python runpod_em_nerf_test.py
   ```

4. ê¸°ëŒ€ ì„±ëŠ¥ (RTX 4090 ê¸°ì¤€)
   - í›ˆë ¨ ì†ë„: 50-100 epoch/ë¶„
   - ì¶”ë¡  ì†ë„: 1000+ samples/ì´ˆ
   - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 8-12GB

5. ê²°ê³¼ íŒŒì¼ë“¤
   - em_nerf_model_*.pth: í›ˆë ¨ëœ ëª¨ë¸
   - em_nerf_benchmark_*.json: ì„±ëŠ¥ ë¦¬í¬íŠ¸  
   - em_field_visualization_*.png: ì‹œê°í™” ê²°ê³¼

6. ë¹„ìš© ìµœì í™” íŒ
   - Spot ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©ìœ¼ë¡œ 50% ë¹„ìš© ì ˆì•½
   - í•„ìš”ì‹œì—ë§Œ GPU ì‚¬ìš©, ìœ íœ´ì‹œ ì •ì§€
   - ë°ì´í„° ì „ì²˜ë¦¬ëŠ” CPU ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ìˆ˜í–‰

ğŸ’¡ ë¬¸ì œ í•´ê²°
===========
- GPU ë©”ëª¨ë¦¬ ë¶€ì¡±: ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸° (batch_size=16 ë˜ëŠ” 8)
- ëŠë¦° í›ˆë ¨: mixed precision í™œì„±í™” í™•ì¸
- ë°ì´í„° ë¡œë”© ëŠë¦¼: num_workers ì¡°ì •

ğŸ“Š ì‹¤ì œ ë°ì´í„°ì…‹ ì‚¬ìš©ë²•
====================
1. NIST RF ë°ì´í„°: https://its.ntia.gov/public-data/
2. DeepSig RadioML: https://www.deepsig.ai/datasets/
3. ìì²´ ì¸¡ì • ë°ì´í„°: convert_matlab_to_pytorch() í•¨ìˆ˜ ì‚¬ìš©

ğŸ”— ì¶”ê°€ ë¦¬ì†ŒìŠ¤
=============
- NeRF ë…¼ë¬¸: https://arxiv.org/abs/2003.08934
- Instant-NGP: https://arxiv.org/abs/2201.05989
- RF ì „íŒŒ ëª¨ë¸ë§: https://www.itu.int/rec/R-REC-P/en
"""
    
    print(guide)

# ì¶”ê°€ ì‹¤í–‰ ì˜µì…˜ë“¤
if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        command = sys.argv[1]
        
        if command == "guide":
            print_runpod_guide()
        elif command == "memory":
            memory_profiler()
        elif command == "compare":
            run_comparative_benchmark()
        elif command == "setup":
            create_runpod_setup_script()
            download_real_datasets()
        else:
            print("ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´. ì‚¬ìš©ë²•: python script.py [guide|memory|compare|setup]")
    else:
        # ê¸°ë³¸ ì‹¤í–‰: ì „ì²´ ë²¤ì¹˜ë§ˆí¬
        main_results = run_full_benchmark()
        
        # ì¶”ê°€ ë¶„ì„ ì‹¤í–‰
        print("\nì¶”ê°€ ë¶„ì„ ì‹¤í–‰ ì¤‘...")
        memory_results = memory_profiler()
        comparison_results = run_comparative_benchmark()
        
        print("\nğŸ‰ ëª¨ë“  ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")
        print("ìì„¸í•œ ê°€ì´ë“œë¥¼ ë³´ë ¤ë©´: python script.py guide")